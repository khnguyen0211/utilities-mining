{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Topic 0: Discovering Top-k periodic high-utility itemsets from uncertain databases**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Classes / Models**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import heapq\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item:\n",
    "    \"\"\"\n",
    "    Represents an item with a utility value and a Transaction Weighted Utility (TWU).\n",
    "\n",
    "    Attributes:\n",
    "        item (str): The identifier or name of the item.\n",
    "        utility (int): The utility value associated with the item.\n",
    "        twu (int): The Transaction Weighted Utility (TWU) of the item. \n",
    "            This is a property with getter and setter methods.\n",
    "    \n",
    "    Methods:\n",
    "        __repr__(): Returns a string representation of the item (its name).\n",
    "        __eq__(other): Checks equality between two items based on their name and utility.\n",
    "        __hash__(): Provides a hash value for the item for use in hash-based collections.\n",
    "    \"\"\"\n",
    "    def __init__(self, item: str, utility: int):\n",
    "        self.item = item\n",
    "        self.utility = utility\n",
    "        self._twu = 0\n",
    "\n",
    "    @property\n",
    "    def twu(self) -> int:\n",
    "        \"\"\"int: Gets or sets the Transaction Weighted Utility (TWU) of the item.\"\"\"\n",
    "        return self._twu\n",
    "\n",
    "    @twu.setter\n",
    "    def twu(self, value: int) -> None:\n",
    "        self._twu = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Returns a string representation of the item (its name).\"\"\"\n",
    "        return f\"{self.item}\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        \"\"\"Checks equality between two items based on their name and utility.\"\"\"\n",
    "        if isinstance(other, Item):\n",
    "            return self.item == other.item and self.utility == other.utility\n",
    "        return False\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"Provides a hash value for the item for use in hash-based collections.\"\"\"\n",
    "        return hash((self.item, self.utility))\n",
    "\n",
    "\n",
    "\n",
    "def check_order_condition(a: Item, b: Item) -> bool:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        a (Item): an item\n",
    "        b (Item): an item\n",
    "\n",
    "    Returns:\n",
    "        bool: return a > b\n",
    "    \"\"\"\n",
    "    if a.utility * b.utility < 0:\n",
    "        return a.utility < b.utility\n",
    "    elif a.utility * b.utility > 0:\n",
    "        if a.twu == b.twu:\n",
    "            if a.utility == b.utility:\n",
    "                return a.item > b.item\n",
    "            return b.utility > a.utility\n",
    "        return a.twu > b.twu\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_order_item_and_set(item: Item, item_set: set[Item]) -> bool:\n",
    "    \"\"\"_summary_\n",
    "    This function is used to check an item > item-set or not.\n",
    "    Example: a > {b, c}\n",
    "    Args:\n",
    "        item (Item): an item\n",
    "        item_set (set[Item]): an item set\n",
    "\n",
    "    Returns:\n",
    "        bool: return item > item_set\n",
    "    \"\"\"\n",
    "    for i in item_set:\n",
    "        if check_order_condition(item, i) == False:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "class TransItem:\n",
    "    def __init__(self, item: Item, quantity: int, probability: float):\n",
    "        self.item = item\n",
    "        self.quantity = quantity\n",
    "        self.probability = probability\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.item},{self.quantity},{self.probability}\"\n",
    "\n",
    "    def get_total_probability(self):\n",
    "        return self.quantity * self.probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Periodic = namedtuple(\"Periodic\", [\"min_per\", \"max_per\", \"avg_per\"])\n",
    "\n",
    "@dataclass\n",
    "class Utilities:\n",
    "    tid: int\n",
    "    pro: float\n",
    "    pu: int\n",
    "    nu: int\n",
    "    ru: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transaction:\n",
    "    def __init__(self, id: int, trans_items: list[TransItem]):\n",
    "        self.id = id\n",
    "        self.trans_items_list = [trans_item.item for trans_item in trans_items]\n",
    "        self.trans_items_dict = {\n",
    "            trans_item.item: (trans_item.quantity, trans_item.probability)\n",
    "            for trans_item in trans_items\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Transaction(id={self.id}, items={list(self.trans_items_dict.keys())}, quantities={list(self.trans_items_dict.values())})\"\n",
    "\n",
    "    def contains_item_set(self, item_set: set[Item]) -> bool:\n",
    "        # Check directly against the dictionary keys\n",
    "        return item_set.issubset(self.trans_items_dict.keys())\n",
    "\n",
    "    def get_quantity_of_item(self, item: Item) -> int:\n",
    "        # Access quantity directly from the dictionary\n",
    "        return self.trans_items_dict.get(item, (0, 0))[0]\n",
    "\n",
    "    def get_probability_of_item(self, item: Item) -> float:\n",
    "        # Access probability directly from the dictionary\n",
    "        return self.trans_items_dict.get(item, (0, 0))[1]\n",
    "\n",
    "    def get_positive_utility_of_trans(self):\n",
    "        put = 0\n",
    "        positive_item = {item for item in self.get_items() if item.utility > 0}\n",
    "        for item in positive_item:\n",
    "            put += item.utility * self.get_quantity_of_item(item)\n",
    "        return put\n",
    "\n",
    "    def get_items(self) -> set[Item]:\n",
    "        return set(self.trans_items_dict.keys())\n",
    "\n",
    "    def get_probability_of_item_set(self, item_set: set[Item]) -> float:\n",
    "        if not self.contains_item_set(item_set):\n",
    "            return 0.0\n",
    "        total_probability = 1.0\n",
    "        for item in item_set:\n",
    "            total_probability *= self.get_probability_of_item(item)\n",
    "        return total_probability\n",
    "\n",
    "    def _calculate_utility(self, item_set: set[Item], condition: callable) -> int:\n",
    "        total_utility = 0\n",
    "        for item in item_set:\n",
    "            quantity = self.get_quantity_of_item(item)\n",
    "            if condition(item.utility):\n",
    "                total_utility += item.utility * quantity\n",
    "        return total_utility\n",
    "\n",
    "    def get_positive_utility_of_item_set(self, item_set: set[Item]) -> int:\n",
    "        return self._calculate_utility(item_set, lambda utility: utility > 0)\n",
    "\n",
    "    def get_negative_utility_of_item_set(self, item_set: set[Item]) -> int:\n",
    "        return self._calculate_utility(item_set, lambda utility: utility < 0)\n",
    "\n",
    "    def get_utility_of_item_set(self, item_set: set[Item]) -> int:\n",
    "        return self._calculate_utility(item_set, lambda utility: True)\n",
    "\n",
    "    def sort_trans_items_by_twu_and_utility(self) -> None:\n",
    "        def sort_key(item: Item) -> tuple:\n",
    "            return (0 if item.utility > 0 else 1, item.twu, -item.utility, item.item)\n",
    "\n",
    "        self.trans_items_list.sort(key=sort_key)\n",
    "\n",
    "    def get_remaining_utility_of_item_set(self, item_set: list[Item]) -> int:\n",
    "        ru = 0\n",
    "        if item_set:\n",
    "            last_item = item_set[-1]\n",
    "            index = self.trans_items_list.index(last_item)\n",
    "            for i in range(index + 1, len(self.trans_items_list)):\n",
    "                item = self.trans_items_list[i]\n",
    "                if item.utility > 0 and item not in item_set:\n",
    "                    quantity = self.trans_items_dict[item][0]\n",
    "                    ru += item.utility * quantity\n",
    "        return ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractList:\n",
    "    def __init__(self, item_set: set[\"Item\"], utility_values: list[\"Utilities\"]):\n",
    "        self.item_set = item_set\n",
    "        self.utility_values = utility_values\n",
    "\n",
    "    def get_ru(self) -> int:\n",
    "        return sum(i.ru for i in self.utility_values)\n",
    "\n",
    "    def get_pu(self) -> int:\n",
    "        return sum(i.pu for i in self.utility_values)\n",
    "\n",
    "    def get_nu(self) -> int:\n",
    "        return sum(i.nu for i in self.utility_values)\n",
    "\n",
    "    def get_pro(self) -> float:\n",
    "        return sum(i.pro for i in self.utility_values)\n",
    "\n",
    "    def get_utility(self) -> int:\n",
    "        return sum(i.pu + i.nu for i in self.utility_values)\n",
    "\n",
    "    def __repr__(self):\n",
    "        items_str = \", \".join(str(item) for item in self.item_set)\n",
    "        utility_values_str = \", \\n\".join(\n",
    "            str(utility) for utility in self.utility_values\n",
    "        )\n",
    "        return f\"{self.__class__.__name__}(\\n  Items: [{items_str}]\\n  Utility Values: \\n[{utility_values_str}]\\n)\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, AbstractList):\n",
    "            return False\n",
    "        return (\n",
    "            self.item_set == other.item_set\n",
    "            and self.utility_values == other.utility_values\n",
    "        )\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(frozenset(self.item_set)) ^ hash(tuple(self.utility_values))\n",
    "\n",
    "\n",
    "class PNUList(AbstractList):\n",
    "    def __init__(self, item_set: set[\"Item\"], utility_values: list[\"Utilities\"]):\n",
    "        super().__init__(item_set, utility_values)\n",
    "\n",
    "\n",
    "class MList(AbstractList):\n",
    "    def __init__(\n",
    "        self,\n",
    "        item_set: set[\"Item\"],\n",
    "        subset: PNUList,\n",
    "        subset_prefix: PNUList,\n",
    "        utility_values: list[\"Utilities\"],\n",
    "        pu: int,\n",
    "        ru: int,\n",
    "    ):\n",
    "        super().__init__(item_set, utility_values)\n",
    "        self.subset = subset\n",
    "        self.subset_prefix = subset_prefix\n",
    "        self.pu = pu\n",
    "        self.ru = ru\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"MList(\"\n",
    "            f\"item_set={list(self.item_set)}, \"\n",
    "            f\"subset={self.subset}, \"\n",
    "            f\"subset_prefix={self.subset_prefix})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityQueue:\n",
    "    def __init__(self, max_size: int):\n",
    "        self.max_size = max_size\n",
    "        self.heap: list[tuple[int, set[Item], Periodic]] = []\n",
    "        self.item_sets: set[frozenset] = set()\n",
    "\n",
    "    def push(self, utility: int, item_set: set, periodic: Periodic):\n",
    "        fs_item_set = frozenset(item_set)\n",
    "        if fs_item_set in self.item_sets:\n",
    "            return\n",
    "\n",
    "        if len(self.heap) < self.max_size:\n",
    "            heapq.heappush(self.heap, (utility, item_set, periodic))\n",
    "            self.item_sets.add(fs_item_set)\n",
    "        else:\n",
    "            if utility > self.heap[0][0]:\n",
    "                removed = heapq.heappushpop(self.heap, (utility, item_set, periodic))\n",
    "                self.item_sets.remove(frozenset(removed[1]))\n",
    "                self.item_sets.add(fs_item_set)\n",
    "\n",
    "    def get_min_utility(self) -> int:\n",
    "        if self.heap:\n",
    "            return self.heap[0][0]\n",
    "        return float(\"-inf\")\n",
    "\n",
    "    def sort(self) -> list[tuple[int, set[Item], Periodic]]:\n",
    "        return sorted(self.heap, reverse=True)\n",
    "\n",
    "    def print_items(self):\n",
    "        for utility, item_set, periodic in self.sort():\n",
    "            formatted_periodic = f\"(min_per={periodic.min_per}, max_per={periodic.max_per}, avg_per={periodic.avg_per:.2f})\"\n",
    "            print(f\"{item_set} : {utility} : {formatted_periodic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Preliminaries and Formulation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.0. Transaction Dictionary**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transaction_dictionary(item_list: list[Item], database: list[Transaction]):\n",
    "    trans_dict: dict[Item, set[Transaction]] = {item: set() for item in item_list}\n",
    "    for trans in database:\n",
    "        trans_items = trans.get_items()\n",
    "        for item in trans_items:\n",
    "            trans_dict.get(item).add(trans)\n",
    "    return trans_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.1. Periodic Pattern**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_transId_dict(\n",
    "    item_list: list[Item], db: list[Transaction]\n",
    ") -> dict[Item, list[int]]:\n",
    "    transaction_index = {item: list() for item in item_list}\n",
    "    for trans in db:\n",
    "        for item in trans.trans_items_dict.keys():\n",
    "            transaction_index[item].append(trans.id)\n",
    "    return transaction_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_trans_ids_contained_item_set(\n",
    "    item_set: set[Item], create_item_transId_dict: dict[Item, list[int]]\n",
    ") -> list[int]:\n",
    "    trans_ids = list()\n",
    "    for item in item_set:\n",
    "        if not trans_ids:\n",
    "            trans_ids = set(create_item_transId_dict[item])\n",
    "            continue\n",
    "        trans_ids &= set(create_item_transId_dict[item])\n",
    "    return sorted(trans_ids) if trans_ids else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_max_avg_periodic_of_item_set(\n",
    "    item_set: set[Item], db: list[Transaction], transaction_index: dict[Item, list[int]]\n",
    ") -> Periodic:\n",
    "    trans_ids = find_all_trans_ids_contained_item_set(item_set, transaction_index)\n",
    "    if not trans_ids:\n",
    "        return Periodic(0, 0, 0)\n",
    "\n",
    "    m = len(trans_ids)\n",
    "    max_per, min_per, total_per = 0, float(\"inf\"), 0\n",
    "    prev = 0\n",
    "    for _, trans_id in enumerate(trans_ids):\n",
    "        per = trans_id - prev\n",
    "        max_per = max(max_per, per)\n",
    "        min_per = min(min_per, per)\n",
    "        total_per += per\n",
    "        prev = trans_id\n",
    "    final_per = len(db) - prev\n",
    "    max_per = max(max_per, final_per)\n",
    "    min_per = min(min_per, final_per)\n",
    "    total_per += final_per\n",
    "    avg_per = total_per / (m + 1)\n",
    "    return Periodic(min_per, max_per, avg_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.1 Transaction Weight Utility**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transaction_weight_utility(\n",
    "    item_set: set[Item], database: list[Transaction]\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Calculates the Transaction Weighted Utility (TWU) for a given item set.\n",
    "\n",
    "    Args:\n",
    "        item_set (set[Item]): The set of items for which the TWU is calculated.\n",
    "        database (list[Transaction]): The list of transactions in the database.\n",
    "\n",
    "    Returns:\n",
    "        twu (int): The total Transaction Weighted Utility (TWU) of the item set.\n",
    "    \"\"\"\n",
    "    twu = 0\n",
    "    for trans in database:\n",
    "        if trans.contains_item_set(item_set):\n",
    "            twu += trans.get_positive_utility_of_trans()\n",
    "    return twu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.3. Utility of an Itemset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_utility_of_item_set_in_database(\n",
    "    item_set: set[Item], trans_dict: dict[Item, set[Transaction]]\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Calculates the utility of an item set in the database.\n",
    "\n",
    "    Args:\n",
    "        item_set (set[Item]): The set of items whose utility is to be calculated.\n",
    "        trans_dict (dict[Item, set[Transaction]]): A dictionary mapping each item to the\n",
    "            set of transactions in which it appears. \n",
    "\n",
    "    Returns:\n",
    "        utility (int): The total utility of the item set across all transactions.\n",
    "    \"\"\"\n",
    "    transaction_set: set[Transaction] = set()\n",
    "\n",
    "    # Intersect transactions for all items in the item set\n",
    "    for item in item_set:\n",
    "        if not transaction_set:\n",
    "            transaction_set = set(trans_dict[item])\n",
    "            continue\n",
    "        transaction_set &= set(trans_dict[item])\n",
    "\n",
    "    # Calculate the utility of the item set in the intersected transactions\n",
    "    utility = 0\n",
    "    for trans in transaction_set:\n",
    "        utility += trans.get_utility_of_item_set(item_set)\n",
    "\n",
    "    return utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Order of items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_order_condition(a: Item, b: Item) -> bool:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        a (Item): an item\n",
    "        b (Item): an item\n",
    "\n",
    "    Returns:\n",
    "        bool: return b < a\n",
    "    \"\"\"\n",
    "    if a.utility * b.utility < 0:\n",
    "        return a.utility < b.utility\n",
    "    elif a.utility * b.utility > 0:\n",
    "        if a.twu == b.twu:\n",
    "            if a.utility == b.utility:\n",
    "                return a.item > b.item\n",
    "            return b.utility > a.utility\n",
    "        return a.twu > b.twu\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_order_item_and_set(item: Item, item_set: set[Item]) -> bool:\n",
    "    \"\"\"_summary_\n",
    "    This function is used to check an item > item-set or not.\n",
    "    Example: a > {b, c}\n",
    "    Args:\n",
    "        item (Item): an item\n",
    "        item_set (set[Item]): an item set\n",
    "\n",
    "    Returns:\n",
    "        bool: return item > item_set\n",
    "    \"\"\"\n",
    "    for i in item_set:\n",
    "        if check_order_condition(item, i) == False:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_items_by_twu_and_utility(items: list[Item]) -> list[Item]:\n",
    "    \"\"\"\n",
    "    Sorts a list of items based on Transaction Weighted Utility (TWU) and utility.\n",
    "\n",
    "    Items are sorted by the following criteria in order of priority:\n",
    "        1. Items with positive utility appear before items with negative utility.\n",
    "        2. Items with higher TWU values are sorted first.\n",
    "        3. For items with the same TWU, those with higher utility values are sorted first.\n",
    "        4. For items with the same TWU and utility, sorting is done alphabetically by item name.\n",
    "\n",
    "    Args:\n",
    "        items (list[Item]): The list of items to be sorted.\n",
    "\n",
    "    Returns:\n",
    "        list[Item]: The sorted list of items.\n",
    "    \"\"\"\n",
    "    def sort_key(item: Item) -> tuple:\n",
    "        return (0 if item.utility > 0 else 1, item.twu, -item.utility, item.item)\n",
    "\n",
    "    return sorted(items, key=sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.4. Potential / Expected Pattern**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability_of_item_set_in_database(\n",
    "    item_set: set[Item], trans_dict: dict[Item, set[Transaction]]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculates the combined probability of an item set across transactions in the database.\n",
    "\n",
    "    The combined probability of an item set is calculated as the product of the probabilities\n",
    "    of the item set in all transactions where it appears. \n",
    "    \n",
    "    Args:\n",
    "        item_set (set[Item]): The set of items whose probability is to be calculated.\n",
    "        trans_dict (dict[Item, set[Transaction]]): A dictionary mapping each item to the\n",
    "            set of transactions in which it appears.\n",
    "\n",
    "    Returns:\n",
    "        probability (float): The combined probability of the item set across all relevant transactions.\n",
    "            Returns 0.0 if the item set does not appear in any transaction.\n",
    "    \"\"\"\n",
    "    transaction_set: set[Transaction] = set()\n",
    "\n",
    "    # Intersect transactions for all items in the item set\n",
    "    for item in item_set:\n",
    "        if not transaction_set:\n",
    "            transaction_set = set(trans_dict[item])\n",
    "            continue\n",
    "        transaction_set &= set(trans_dict[item])\n",
    "\n",
    "    # If no transactions contain the full item set, return 0\n",
    "    if not transaction_set:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate the combined probability for the item set\n",
    "    probability = 1.0\n",
    "    for trans in transaction_set:\n",
    "        probability *= trans.get_probability_of_item_set(item_set)\n",
    "\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability_and_utility_of_item_set_in_database(\n",
    "    item_set: set[Item], trans_dict: dict[Item, set[Transaction]]\n",
    ") -> tuple[float, int, int]:\n",
    "    \"\"\"\n",
    "    Calculates the probability, utility, and remaining utility (RU) of an item set\n",
    "    in the database based on its transactions.\n",
    "\n",
    "    Args:\n",
    "        item_set (set[Item]): The set of items whose probability, utility, and\n",
    "            remaining utility are to be calculated.\n",
    "        trans_dict (dict[Item, set[Transaction]]): A dictionary mapping each item\n",
    "            to the set of transactions in which it appears. \n",
    "\n",
    "    Returns:\n",
    "        (p, u, ru) (tuple[float, int, int]): A tuple containing:\n",
    "            - p (float): The combined probability of the item set across all transactions.\n",
    "            - u (int): The total utility of the item set across all transactions.\n",
    "            - ru (int): The remaining utility of the item set, calculated based\n",
    "              on a sorted version of the item set by TWU and utility.\n",
    "    \"\"\"\n",
    "    # Intersect transactions for all items in the item set\n",
    "    intersection_trans = set()\n",
    "    for item in item_set:\n",
    "        if not intersection_trans:\n",
    "            intersection_trans = set(trans_dict.get(item, set()))\n",
    "            continue\n",
    "        intersection_trans &= trans_dict.get(item)\n",
    "    p: float = 0.0\n",
    "    u: int = 0\n",
    "    ru: int = 0\n",
    "    sorted_itemset = sort_items_by_twu_and_utility(item_set)\n",
    "    # Calculate the probability, utility, remaining utility for the item set\n",
    "    for trans in intersection_trans:\n",
    "        p += trans.get_probability_of_item_set(item_set)\n",
    "        u += trans.get_utility_of_item_set(item_set)\n",
    "        ru += trans.get_remaining_utility_of_item_set(sorted_itemset)\n",
    "    return p, u, ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.4. Probability - TWU - Utility Bin Array**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prob_twu_utility_bin_array(\n",
    "    item_list: set[Item], database: list[Transaction]\n",
    ") -> tuple[list[int], list[int], list[int], dict[Item, int]]:\n",
    "    \"\"\"\n",
    "    Creates arrays for probability, Transaction Weighted Utility (TWU), and utility\n",
    "    for all items in the given item list based on their occurrences in the database.\n",
    "\n",
    "    Args:\n",
    "        item_list (set[Item]): The set of items to be analyzed.\n",
    "        database (list[Transaction]): A list of transactions where each transaction\n",
    "            provides methods to retrieve items, probabilities, and quantities.\n",
    "\n",
    "    Returns:\n",
    "        (prob_array, twu_array, utility_array, item_dict) (tuple[list[int], list[int], list[int], dict[Item, int]]):\n",
    "            - prob_array (list[int]): An array where each element represents the summed\n",
    "              probability of an item across all transactions.\n",
    "            - twu_array (list[int]): An array where each element represents the Transaction\n",
    "              Weighted Utility (TWU) of an item.\n",
    "            - utility_array (list[int]): An array where each element represents the total\n",
    "              utility of an item (calculated as quantity * utility).\n",
    "            - item_dict (dict[Item, int]): A dictionary mapping each item to its index in\n",
    "              the arrays for fast access.\n",
    "    \"\"\"\n",
    "    n = len(item_list)\n",
    "    # Initialize arrays to store TWU, probability, and utility for each item\n",
    "    twu_array = [0 for _ in range(n)]\n",
    "    prob_array = [0 for _ in range(n)]\n",
    "    utility_array = [0 for _ in range(n)]\n",
    "\n",
    "    # Map each item to an index in the arrays for efficient lookups\n",
    "    item_dict = {item: idx for idx, item in enumerate(item_list)}\n",
    "\n",
    "    # Iterate through all transactions to compute values\n",
    "    for trans in database:\n",
    "        # Get the Positive Utility (PTU) of the current transaction\n",
    "        ptu = trans.get_positive_utility_of_trans()\n",
    "\n",
    "        # Update TWU, probability, and utility for each item in the transaction\n",
    "        for item in trans.get_items():\n",
    "            index = item_dict.get(item, -1)  # Get the index of the item in the arrays\n",
    "            if index != -1:  # If the item exists in the item_dict\n",
    "                twu_array[index] += ptu  # Add transaction's PTU to the item's TWU\n",
    "                prob_array[index] += trans.get_probability_of_item(\n",
    "                    item\n",
    "                )  # Add probability\n",
    "                utility_array[index] += (\n",
    "                    trans.get_quantity_of_item(item) * item.utility\n",
    "                )  # Add utility\n",
    "\n",
    "    # Return the computed arrays and the item dictionary\n",
    "    return prob_array, twu_array, utility_array, item_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Remaining Utility**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_remaining_utility_of_item_set_in_database(\n",
    "    item_set: set[Item], trans_dict: dict[Item, set[Transaction]]\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Calculates the remaining utility of an item set in the database.\n",
    "\n",
    "    The remaining utility of an item set is the sum of the remaining utilities\n",
    "    in all transactions where the item set appears.\n",
    "\n",
    "    Args:\n",
    "        item_set (set[Item]): The set of items whose remaining utility is to be calculated.\n",
    "        trans_dict (dict[Item, set[Transaction]]): A dictionary mapping each item to the\n",
    "            set of transactions in which it appears. This dictionary helps to efficiently\n",
    "            find transactions that contain the given item set.\n",
    "\n",
    "    Returns:\n",
    "        ru (int): The total remaining utility of the item set across all relevant transactions.\n",
    "    \"\"\"\n",
    "    transaction_set: set[Transaction] = set()\n",
    "\n",
    "    # Find the intersection of transactions that contain all items in the item set\n",
    "    for item in item_set:\n",
    "        if not transaction_set:\n",
    "            transaction_set = set(\n",
    "                trans_dict[item]\n",
    "            )  # Initialize with transactions of the first item\n",
    "            continue\n",
    "        transaction_set &= set(\n",
    "            trans_dict[item]\n",
    "        )  # Perform intersection with subsequent item transactions\n",
    "\n",
    "    # Calculate the remaining utility for the item set in the intersected transactions\n",
    "    utility = 0\n",
    "    for trans in transaction_set:\n",
    "        # Add the remaining utility of the item set in the current transaction\n",
    "        utility += trans.get_remaining_utility_of_item_set(item_set)\n",
    "\n",
    "    # Return the total remaining utility\n",
    "    return utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Local Utility**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_local_utility(\n",
    "    alpha: set[Item], item: Item, database: list[Transaction]\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Calculates the local utility (LU) of an item combined with an item set (alpha) in the database.\n",
    "\n",
    "    Args:\n",
    "        alpha (set[Item]): The prefix item set (alpha) to calculate the utility for.\n",
    "        item (Item): The item to be combined with alpha for utility calculation.\n",
    "        database (list[Transaction]): A list of transactions \n",
    "\n",
    "    Returns:\n",
    "        lu (int): The total local utility (LU) of the combined item set (alpha | {item}) across all relevant transactions.\n",
    "    \"\"\"\n",
    "    lu = 0\n",
    "\n",
    "    # Sort the prefix item set (alpha) by TWU and utility\n",
    "    sorted_alpha = sort_items_by_twu_and_utility(alpha)\n",
    "\n",
    "    # Iterate through all transactions in the database\n",
    "    for trans in database:\n",
    "        # Check if the transaction contains the combined item set (alpha | {item})\n",
    "        if trans.contains_item_set(alpha | {item}):\n",
    "            # Add the utility of alpha and the remaining utility of sorted alpha\n",
    "            lu += trans.get_utility_of_item_set(\n",
    "                alpha\n",
    "            ) + trans.get_remaining_utility_of_item_set(sorted_alpha)\n",
    "\n",
    "    # Return the total local utility\n",
    "    return lu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Subtree Utility**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_subtree_utility(\n",
    "    alpha: set[Item],\n",
    "    item: Item,\n",
    "    beta_db: set[Transaction],\n",
    "    trans_dict: dict[Item, set[Transaction]],\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Calculates the subtree utility (SU) of an item combined with an item set (alpha)\n",
    "    within a subset of the database.\n",
    "\n",
    "    Args:\n",
    "        alpha (set[Item]): The prefix item set (alpha) for utility calculation.\n",
    "        item (Item): The item to be combined with alpha.\n",
    "        beta_db (set[Transaction]): The subset of transactions (beta database) relevant for calculation.\n",
    "        trans_dict (dict[Item, set[Transaction]]): A dictionary mapping each item to the\n",
    "            set of transactions in which it appears.\n",
    "\n",
    "    Returns:\n",
    "        su (int): The total subtree utility (SU) of the combined item set (alpha | {item}) across all relevant transactions.\n",
    "    \"\"\"\n",
    "    # Retrieve the set of transactions containing the item\n",
    "    item_trans: set[Transaction] = set(trans_dict.get(item))\n",
    "\n",
    "    # Find the intersection of transactions containing the item and those in beta_db\n",
    "    general_trans: set[Transaction] = item_trans & beta_db\n",
    "\n",
    "    # Initialize subtree utility\n",
    "    su = 0\n",
    "\n",
    "    # Sort the prefix item set (alpha) by TWU and utility\n",
    "    sorted_alpha = sort_items_by_twu_and_utility(alpha)\n",
    "\n",
    "    # Check the order condition if alpha is non-empty\n",
    "    if not alpha or check_order_condition(item, sorted_alpha[-1]):\n",
    "        for trans in general_trans:\n",
    "            # Add utility contributions from alpha, item, and remaining utility of item\n",
    "            su += (\n",
    "                trans.get_utility_of_item_set(alpha)\n",
    "                + trans.get_utility_of_item_set({item})\n",
    "                + trans.get_remaining_utility_of_item_set([item])\n",
    "            )\n",
    "\n",
    "    # Return the total subtree utility\n",
    "    return su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Local & Subtree Utility Bin Array**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_local_subtree_bin_array(\n",
    "    alpha: set[Item], item_list: set[Item], database: list[Transaction]\n",
    ") -> tuple[list[int], list[int], list[float]]:\n",
    "    n = len(item_list)\n",
    "    lu_array = [0 for _ in range(n)]\n",
    "    su_array = [0 for _ in range(n)]\n",
    "    item_dict = {item: idx for idx, item in enumerate(item_list)}\n",
    "    sorted_alpha = sort_items_by_twu_and_utility(alpha)\n",
    "    set_item = set(item_list)\n",
    "    for trans in database:\n",
    "        alpha_util = trans.get_utility_of_item_set(alpha)\n",
    "        alpha_ru = trans.get_remaining_utility_of_item_set(sorted_alpha)\n",
    "        for item in trans.get_items():\n",
    "            index = item_dict.get(item, -1)\n",
    "            if index != -1:\n",
    "                lu_array[index] += alpha_util + alpha_ru\n",
    "                if item in set_item:\n",
    "                    item_utility = trans.get_quantity_of_item(item) * item.utility\n",
    "                    item_ru = trans.get_remaining_utility_of_item_set([item])\n",
    "                    if not alpha:\n",
    "                        su_array[index] += alpha_util + item_utility + item_ru\n",
    "                    else:\n",
    "                        if check_order_condition(item, sorted_alpha[-1]):\n",
    "                            su_array[index] += alpha_util + item_utility + item_ru\n",
    "    return lu_array, su_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_local_utility_bin_array(\n",
    "    alpha: set[Item], item_list: set[Item], database: list[Transaction]\n",
    "):\n",
    "    n = len(item_list)\n",
    "    lu_array = [0 for _ in range(n)]\n",
    "    item_dict = {item: idx for idx, item in enumerate(item_list)}\n",
    "    sorted_alpha = sort_items_by_twu_and_utility(alpha)\n",
    "    for trans in database:\n",
    "        alpha_util = trans.get_utility_of_item_set(alpha)\n",
    "        alpha_ru = trans.get_remaining_utility_of_item_set(sorted_alpha)\n",
    "        for item in trans.get_items():\n",
    "            index = item_dict.get(item, -1)\n",
    "            if index != -1:\n",
    "                lu_array[index] += alpha_util + alpha_ru\n",
    "    return lu_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subtree_utility_bin_array(\n",
    "    alpha: set[Item], item_list: set[Item], database: list[Transaction]\n",
    "):\n",
    "    n = len(item_list)\n",
    "    su_array = [0 for _ in range(n)]\n",
    "    item_dict = {item: idx for idx, item in enumerate(item_list)}\n",
    "    sorted_alpha = sort_items_by_twu_and_utility(alpha)\n",
    "    for trans in database:\n",
    "        alpha_util = trans.get_utility_of_item_set(alpha)\n",
    "        for item in trans.get_items():\n",
    "            index = item_dict.get(item, -1)\n",
    "            if index != -1:\n",
    "                if not alpha or check_order_condition(item, sorted_alpha[-1]):\n",
    "                    su_array[index] += (\n",
    "                        alpha_util\n",
    "                        + trans.get_utility_of_item_set({item})\n",
    "                        + trans.get_remaining_utility_of_item_set([item])\n",
    "                    )\n",
    "    return su_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_from_bin(\n",
    "    item: Item, bin: list[int | float], item_dict: dict[Item, int | float]\n",
    ") -> int | float:\n",
    "    \"\"\"\n",
    "\n",
    "    This function uses a dictionary item_dict to map the item to its index in the bin array.\n",
    "    If the item is not found in the dictionary, it returns a default value of 0.\n",
    "\n",
    "    Args:\n",
    "        item (Item): The item for which the value needs to be retrieved.\n",
    "        bin (list[int | float]): The bin array containing values corresponding to items.\n",
    "        item_dict (dict[Item, int | float]): A dictionary mapping each item to its index in the bin array.\n",
    "\n",
    "    Returns:\n",
    "        values (int | float): The value associated with the item in the bin array.\n",
    "                     Returns 0 if the item is not found in the dictionary.\n",
    "    \"\"\"\n",
    "    # Get the index of the item from the dictionary\n",
    "    index = item_dict.get(item, -1)\n",
    "\n",
    "    # Return the value from the bin array if the index is valid, otherwise return 0\n",
    "    return bin[index] if index != -1 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 PNU List & MList**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pnu_lists(trans_dict: dict[Item, set[Transaction]]) -> list[PNUList]:\n",
    "    \"\"\"\n",
    "    Creates a list of PNULists, each representing an item's utility and probability \n",
    "    values across all transactions in which it appears.\n",
    "\n",
    "    A PNUList contains:\n",
    "        - The item as a set.\n",
    "        - A list of utility values (probability, positive utility, negative utility, \n",
    "          and remaining utility) for each transaction.\n",
    "\n",
    "    Args:\n",
    "        trans_dict (dict[Item, set[Transaction]]): A dictionary mapping each item to \n",
    "            the set of transactions in which it appears.\n",
    "\n",
    "    Returns:\n",
    "        list[PNUList]: A list of PNULists where each PNUList corresponds to an item \n",
    "                       and contains its utility and probability values across relevant transactions.\n",
    "    \"\"\"\n",
    "    pnu_list = []\n",
    "\n",
    "    # Iterate through each item and its associated transactions in trans_dict\n",
    "    for item, transactions in trans_dict.items():\n",
    "        utility_values_list = []  # List to store utility values for the current item\n",
    "\n",
    "        # Create a PNUList for the current item\n",
    "        pnu = PNUList({item}, utility_values_list)\n",
    "\n",
    "        # Calculate utility values for the item in each transaction\n",
    "        for trans in transactions:\n",
    "            # Get utility values from the transaction\n",
    "            pro = trans.get_probability_of_item_set({item})  # Probability of the item\n",
    "            pu = trans.get_positive_utility_of_item_set({item})  # Positive utility of the item\n",
    "            nu = trans.get_negative_utility_of_item_set({item})  # Negative utility of the item\n",
    "            ru = trans.get_remaining_utility_of_item_set([item])  # Remaining utility of the item\n",
    "\n",
    "            # Create a Utilities object to store values for the transaction\n",
    "            utility_values = Utilities(trans.id, pro, pu, nu, ru)\n",
    "\n",
    "            # Add the utility values to the list for this item\n",
    "            utility_values_list.append(utility_values)\n",
    "\n",
    "        # Add the PNUList for this item to the main list\n",
    "        pnu_list.append(pnu)\n",
    "\n",
    "    # Return the list of PNULists\n",
    "    return pnu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tuple_by_trans_id(P: PNUList, target_trans_id: int) -> Utilities | None:\n",
    "    \"\"\"\n",
    "    Finds a `Utilities` tuple in the utility values of a PNUList by transaction ID.\n",
    "\n",
    "    Args:\n",
    "        P (PNUList): The PNUList object containing utility values as a list of `Utilities` objects.\n",
    "        target_trans_id (int): The transaction ID to search for.\n",
    "\n",
    "    Returns:\n",
    "        Utilities | None: The `Utilities` object with the matching transaction ID if found.\n",
    "                          Returns `None` if no match is found.\n",
    "    \"\"\"\n",
    "    # Get the list of Utilities objects from the PNUList\n",
    "    utilities_list: list[Utilities] = P.utility_values\n",
    "\n",
    "    # Iterate through each Utilities object to find the one with the matching transaction ID\n",
    "    for iTuple in utilities_list:\n",
    "        if iTuple.tid == target_trans_id:  # Match found\n",
    "            return iTuple\n",
    "\n",
    "    # Return None if no matching transaction ID is found\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_list_construct(\n",
    "    P: PNUList,\n",
    "    Px: PNUList,\n",
    "    Py: PNUList,\n",
    "    min_util: int,\n",
    "    user_prob_threshold: float,\n",
    ") -> PNUList | None:\n",
    "    \"\"\"\n",
    "    Constructs the utility list for the combined item set (Px U Py) by processing\n",
    "    the utility lists of two item sets (Px and Py) with optional reference to a\n",
    "    parent item set (P).\n",
    "\n",
    "    Args:\n",
    "        P (PNUList): The parent PNUList containing the utility values of the combined items' parent set.\n",
    "                     It can be used for normalization or overlap calculations.\n",
    "        Px (PNUList): The PNUList of the first item set.\n",
    "        Py (PNUList): The PNUList of the second item set.\n",
    "        min_util (int): The minimum utility threshold for the combined item set.\n",
    "        user_prob_threshold (float): The minimum probability threshold for the combined item set.\n",
    "\n",
    "    Returns:\n",
    "        PNUList | None: The PNUList for the combined item set (Px ∪ Py) if it satisfies the\n",
    "                        given thresholds. \n",
    "    \"\"\"\n",
    "    # Check if Px or Py is empty or has no utility values\n",
    "    if not Px or not Py or not Px.utility_values or not Py.utility_values:\n",
    "        return None\n",
    "\n",
    "    # Combine the item sets of Px and Py\n",
    "    x = Px.item_set\n",
    "    y = Py.item_set\n",
    "    xy = x | y\n",
    "\n",
    "    # Initialize the utility list for the combined item set\n",
    "    utilities_list: list[Utilities] = []\n",
    "    Pxy = PNUList(xy, utilities_list)\n",
    "\n",
    "    # Create dictionaries for fast lookup of utility values by transaction ID\n",
    "    y_dict = {utl.tid: utl for utl in Py.utility_values}\n",
    "    p_dict = (\n",
    "        {utl.tid: utl for utl in P.utility_values} if P and P.utility_values else {}\n",
    "    )\n",
    "\n",
    "    # Initialize combined probability and utility\n",
    "    probability = Px.get_pro()\n",
    "    utility = Px.get_pu() + Px.get_ru()\n",
    "\n",
    "    # Iterate through the utility values of Px\n",
    "    for xTuple in Px.utility_values:\n",
    "        yTuple = y_dict.get(xTuple.tid, None)  # Find matching utility in Py\n",
    "\n",
    "        if yTuple:  # If both Px and Py have values for the same transaction\n",
    "            if P and P.utility_values:  # If parent PNUList (P) is provided\n",
    "                pTuple = p_dict.get(xTuple.tid, None)  # Find matching utility in P\n",
    "                if pTuple:\n",
    "                    # Calculate utility values for the combined item set\n",
    "                    pro = (\n",
    "                        1e-10 if pTuple.pro == 0 else pTuple.pro\n",
    "                    )  # Avoid division by zero\n",
    "                    xyTuple = Utilities(\n",
    "                        xTuple.tid,\n",
    "                        xTuple.pro * yTuple.pro / pro,\n",
    "                        xTuple.pu + yTuple.pu - pTuple.pu,\n",
    "                        xTuple.nu + yTuple.nu - pTuple.nu,\n",
    "                        yTuple.ru,\n",
    "                    )\n",
    "                    utilities_list.append(xyTuple)\n",
    "            else:  # If parent PNUList (P) is not provided\n",
    "                xyTuple = Utilities(\n",
    "                    xTuple.tid,\n",
    "                    xTuple.pro * yTuple.pro,\n",
    "                    xTuple.pu + yTuple.pu,\n",
    "                    xTuple.nu + yTuple.nu,\n",
    "                    yTuple.ru,\n",
    "                )\n",
    "                utilities_list.append(xyTuple)\n",
    "        else:  # If there is no match in Py\n",
    "            probability -= xTuple.pro\n",
    "            utility -= xTuple.pu + xTuple.ru\n",
    "\n",
    "            # Stop processing if thresholds are not met\n",
    "            if probability < user_prob_threshold or utility < min_util:\n",
    "                return None\n",
    "\n",
    "    # Return the constructed PNUList for the combined item set\n",
    "    return Pxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlist_construct_1(X: AbstractList, Y: MList, du: int) -> MList:\n",
    "    \"\"\"\n",
    "    Constructs an MList object by combining the item sets of two input lists\n",
    "    and initializing utility values based on the given remaining utility (du).\n",
    "\n",
    "    Args:\n",
    "        X (AbstractList): An AbstractList object representing the first list\n",
    "                          of items and their utility values.\n",
    "        Y (MList): An MList object representing the second list of items,\n",
    "                   subsets, and their utility values.\n",
    "        du (int): The dynamic upper bound value for the combined MList.\n",
    "\n",
    "    Returns:\n",
    "        MList: The newly constructed MList object that combines the item sets\n",
    "               from X and Y, while retaining Y's subsets and utility values.\n",
    "    \"\"\"\n",
    "    # Combine the item sets from X and Y\n",
    "    xy_item_set: set[Item] = X.item_set | Y.item_set\n",
    "\n",
    "    # Create a new MList object with combined item sets and initialized utility values\n",
    "    mlist = MList(xy_item_set, Y.subset, Y.subset_prefix, Y.utility_values, 0, du)\n",
    "\n",
    "    # Return the constructed MList\n",
    "    return mlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlist_construct_2(X: AbstractList, Y: PNUList, P: AbstractList, du: int) -> MList:\n",
    "    \"\"\"\n",
    "    Constructs an MList object by combining the item sets of an AbstractList (X)\n",
    "    and a PNUList (Y), while linking it to a parent AbstractList (P) and\n",
    "    initializing utility values based on the given remaining utility (du).\n",
    "\n",
    "    Args:\n",
    "        X (AbstractList): An AbstractList object representing the first list\n",
    "                          of items and their utility values.\n",
    "        Y (PNUList): A PNUList object representing the second list of items,\n",
    "                     subsets, and their utility values.\n",
    "        P (AbstractList): A parent AbstractList object linked to the new MList.\n",
    "        du (int): The dynamic upper bound value for the combined MList.\n",
    "\n",
    "    Returns:\n",
    "        MList: The newly constructed MList object that combines the item sets\n",
    "               from X and Y, links to P, and initializes utility values.\n",
    "    \"\"\"\n",
    "    # Combine the item sets from X and Y\n",
    "    xy_item_set: set[Item] = X.item_set | Y.item_set\n",
    "\n",
    "    # Create a new MList object with combined item sets, linking to Y and P\n",
    "    mlist = MList(xy_item_set, Y, P, Y.utility_values, 0, du)\n",
    "\n",
    "    # Return the constructed MList\n",
    "    return mlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Database Projection**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database_projection(\n",
    "    item_set: set[Item], trans_dict: dict[Item, set[Transaction]]\n",
    ") -> set[Transaction]:\n",
    "    \"\"\"\n",
    "    Creates a projected database by finding the intersection of transactions\n",
    "    that contain all items in the given item set.\n",
    "\n",
    "    Args:\n",
    "        item_set (set[Item]): The set of items for which the projected database\n",
    "                              needs to be created.\n",
    "        trans_dict (dict[Item, set[Transaction]]): A dictionary mapping each item\n",
    "                                                  to the set of transactions in\n",
    "                                                  which it appears.\n",
    "\n",
    "    Returns:\n",
    "        intersection_trans (set[Transaction]): A set of transactions that contain all items in the item set.\n",
    "                          Returns an empty set if no transactions contain all items.\n",
    "    \"\"\"\n",
    "    # Initialize an empty set to store the intersection of transactions\n",
    "    intersection_trans = set()\n",
    "\n",
    "    # Iterate through each item in the item set\n",
    "    for item in item_set:\n",
    "        if not intersection_trans:\n",
    "            # Initialize the intersection with the transactions of the first item\n",
    "            intersection_trans = set(trans_dict.get(item, set()))\n",
    "            continue\n",
    "        # Perform intersection with transactions containing the current item\n",
    "        intersection_trans &= trans_dict.get(item, set())\n",
    "\n",
    "    # Return the final set of intersected transactions\n",
    "    return intersection_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Pruning strategies**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 Max & Average Periodic**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 Transaction Weight Utility**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 The Estimated Utility Co-occurrence pruning Strategy with Threshold (EUCST)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eucst_dict(\n",
    "    sorted_item_list: list[Item],\n",
    "    database: list[Transaction],\n",
    "    trans_dict: dict[Item, set[Transaction]],\n",
    "    min_util: int,\n",
    ") -> dict[frozenset, int]:\n",
    "    \"\"\"\n",
    "    Creates an EUCST (Efficient Utility Co-occurrence Support Threshold) dictionary\n",
    "    for all pairs of items in a sorted item list. The dictionary stores the\n",
    "    Transaction Weighted Utility (TWU) of each item pair that satisfies the minimum utility threshold.\n",
    "\n",
    "    Args:\n",
    "        sorted_item_list (list[Item]): A sorted list of items based on a specific criterion (e.g., TWU).\n",
    "        database (list[Transaction]): A list of transactions where each transaction provides utility values.\n",
    "        trans_dict (dict[Item, set[Transaction]]): A dictionary mapping each item to the set of transactions\n",
    "                                                   in which it appears.\n",
    "        min_util (int): The minimum utility threshold for including item pairs in the EUCST dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict[frozenset, int]: A dictionary where the keys are item pairs represented as frozenset,\n",
    "                              and the values are the TWU of those item pairs.\n",
    "    \"\"\"\n",
    "    # Calculate all positive utility of transaction in database, and store in a dictionary\n",
    "    transaction_twu = {\n",
    "        trans: trans.get_positive_utility_of_trans() for trans in database\n",
    "    }\n",
    "    # Create a dictionary with key is a item and value is a list of transaction that contains item\n",
    "    eucst_dict = {}\n",
    "    n = len(sorted_item_list)\n",
    "    for i in range(n):\n",
    "        item1 = sorted_item_list[i]\n",
    "        for j in range(i + 1, n):\n",
    "            item2 = sorted_item_list[j]\n",
    "            # Using AND operator to get list of transaction that contains item set {item1, item2}\n",
    "            relevant_transactions: set[Transaction] = trans_dict.get(\n",
    "                item1, set()\n",
    "            ) & trans_dict.get(item2, set())\n",
    "            # Calculate sum utility in that transaction list, NOT in database\n",
    "            twu = sum(transaction_twu[trans] for trans in relevant_transactions)\n",
    "            if twu >= min_util:\n",
    "                eucst_dict[frozenset({item1, item2})] = twu\n",
    "    return eucst_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_eucst_dict(\n",
    "    eucst_dict: dict[frozenset, int], min_util: int\n",
    ") -> dict[frozenset, int]:\n",
    "    \"\"\"\n",
    "    Filters an EUCST dictionary to retain only item pairs whose Transaction Weighted Utility (TWU)\n",
    "    meets or exceeds a specified minimum utility threshold.\n",
    "\n",
    "    Args:\n",
    "        eucst_dict (dict[frozenset, int]): A dictionary where keys are item pairs\n",
    "                                           represented as frozenset and values are their TWU.\n",
    "        min_util (int): The minimum utility threshold for retaining item pairs.\n",
    "\n",
    "    Returns:\n",
    "        dict[frozenset, int]: A filtered dictionary containing only the item pairs whose TWU\n",
    "                              is greater than or equal to `min_util`.\n",
    "    \"\"\"\n",
    "    # Filter the dictionary to retain only item pairs with TWU >= min_util\n",
    "    return {key: twu for key, twu in eucst_dict.items() if twu >= min_util}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 The concept of Leaf Itemset Utility (LIU)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_liu_dict(item_list: list, trans_dict: dict[Item, set[Transaction]]) -> dict[frozenset[Item], int]:\n",
    "    \"\"\"\n",
    "    Creates a dictionary of item pairs and their corresponding Local Item Utility (LIU)\n",
    "    based on the common transactions containing those items.\n",
    "\n",
    "    Args:\n",
    "        item_list (list[Item]): A list of items to generate pairs for LIU calculation.\n",
    "        trans_dict (dict[Item, set[Transaction]]): A dictionary mapping each item to the set \n",
    "                                                   of transactions in which it appears.\n",
    "\n",
    "    Returns:\n",
    "        liu_dict (dict[frozenset[Item], int]): A dictionary where the keys are item pairs (represented \n",
    "                                    as frozenset) and the values are the total utility \n",
    "                                    of those pairs across common transactions.\n",
    "    \"\"\"\n",
    "    n = len(item_list)\n",
    "    liu_dict: dict[frozenset[Item], int] = {}\n",
    "    # Generate all pairs of items using nested loops\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            item1 = item_list[i]\n",
    "            item2 = item_list[j]\n",
    "\n",
    "            # Retrieve transactions containing item1 and item2\n",
    "            trans1 = trans_dict.get(item1, set())\n",
    "            trans2 = trans_dict.get(item2, set())\n",
    "\n",
    "            # Find common transactions for the pair\n",
    "            relevant_transactions = trans1 & trans2\n",
    "\n",
    "            # Calculate the utility of the item pair\n",
    "            utility = sum(\n",
    "                trans.get_utility_of_item_set({item1, item2})\n",
    "                for trans in relevant_transactions\n",
    "            )\n",
    "\n",
    "            # Add the pair and its utility to the dictionary\n",
    "            liu_dict[frozenset((item1, item2))] = utility\n",
    "\n",
    "    return liu_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 Remaining Utility Pruning (RM)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 Dynamical Upper Bound**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dynamic_upper_bound(\n",
    "    Y: AbstractList,\n",
    "    X: PNUList,\n",
    "    utility_array: list[int],\n",
    "    item_index_dict: dict[Item, int],\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Calculates the dynamic upper bound (DUB) for a given item set.\n",
    "\n",
    "    The dynamic upper bound is computed by adding the remaining utility (RU),\n",
    "    positive utility (PU), and the utility of the item not shared between the\n",
    "    parent (X) and the current item set (Y).\n",
    "\n",
    "    Args:\n",
    "        Y (AbstractList): The current AbstractList (can be PNUList or MList)\n",
    "                          for which the dynamic upper bound is being calculated.\n",
    "        X (PNUList): The parent PNUList containing the larger item set.\n",
    "        utility_array (list[int]): An array of utility values for items.\n",
    "        item_index_dict (dict[Item, int]): A dictionary mapping each item to\n",
    "                                           its index in the utility array.\n",
    "\n",
    "    Returns:\n",
    "        int: The computed dynamic upper bound for the given item set.\n",
    "    \"\"\"\n",
    "    # Find the item present in X but not in Y\n",
    "    x = next(iter(X.item_set - Y.item_set))\n",
    "\n",
    "    # Initialize the utility of the extra item to 0\n",
    "    x_util = 0\n",
    "\n",
    "    # Get the utility of the extra item if its utility is positive\n",
    "    if x.utility > 0:\n",
    "        x_util = get_value_from_bin(x, utility_array, item_index_dict)\n",
    "\n",
    "    # Calculate the dynamic upper bound based on the type of Y\n",
    "    if isinstance(Y, PNUList):\n",
    "        # For PNUList, use get_ru() and get_pu()\n",
    "        return Y.get_ru() + Y.get_pu() + x_util\n",
    "    elif isinstance(Y, MList):\n",
    "        # For MList, use ru and pu attributes\n",
    "        return Y.ru + Y.pu + x_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Threshold raising strategies**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4.1 Positive Real Item Utility strategy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def priu_pruning(utility_arr: list[int], k: int) -> int:\n",
    "    \"\"\"\n",
    "    Performs Priority Utility (PRIU) pruning by determining the k-th largest utility\n",
    "    value in the given utility array.\n",
    "\n",
    "    Args:\n",
    "        utility_arr (list[int]): A list of utility values to be analyzed.\n",
    "        k (int): The position (1-based index) in the sorted list of utilities to determine.\n",
    "\n",
    "    Returns:\n",
    "        int: The k-th largest utility value if `k` is within the range of the array length.\n",
    "             If `k` is greater than the length of the array or the array is empty, returns 0.\n",
    "    \"\"\"\n",
    "    # Sort the utility array in descending order\n",
    "    sorted_util: list[int] = sorted(utility_arr, reverse=True)\n",
    "\n",
    "    # If the sorted list is empty, return 0\n",
    "    if not sorted_util:\n",
    "        return 0\n",
    "\n",
    "    # Return the k-th largest value if within bounds, otherwise the smallest value in the array\n",
    "    return sorted_util[-1] if k > len(utility_arr) else sorted_util[k - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4.1 Positive LIU-Exact strategy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pliue_strategy(lius: dict[frozenset[Item], int], k: int, current_min_util: int):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        lius (dict[frozenset[Item], int]): _description_\n",
    "        k (int): _description_co\n",
    "        current_min_util (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    piqu_liu = list()\n",
    "    for _, utility in lius.items():\n",
    "        piqu_liu.append(utility)\n",
    "\n",
    "    piqu_liu.sort(reverse=True)\n",
    "\n",
    "    max_index = len(piqu_liu) - 1 if k > len(piqu_liu) else k - 1\n",
    "    if piqu_liu[max_index] > current_min_util:\n",
    "        current_min_util = piqu_liu[max_index]\n",
    "    return current_min_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4.1 COVL strategy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covl_construct(\n",
    "    sorted_list: list[Item],\n",
    "    eucst_dict: dict[frozenset[Item], int],\n",
    "    utility_arr: list[int],\n",
    "    item_index_dict: dict[Item, int],\n",
    "    trans_dict: dict[Item, set[Transaction]],\n",
    ") -> list[int]:\n",
    "    \"\"\"\n",
    "    Constructs a list of Coverage Local Utility (COVL) values for items in a sorted list.\n",
    "\n",
    "    Args:\n",
    "        sorted_list (list[Item]): A list of items sorted based on a specific criterion (e.g., TWU).\n",
    "        eucst_dict (dict[frozenset[Item], int]): A dictionary mapping item pairs to their TWU values.\n",
    "        utility_arr (list[int]): An array of utility values for items.\n",
    "        item_index_dict (dict[Item, int]): A dictionary mapping each item to its index in the utility array.\n",
    "        trans_dict (dict[Item, set[Transaction]]): A dictionary mapping each item to the set of transactions\n",
    "                                                   in which it appears.\n",
    "\n",
    "    Returns:\n",
    "        covl_list (list[int]): A list of COVL values for items, sorted in descending order.\n",
    "    \"\"\"\n",
    "    covl_list = list()\n",
    "\n",
    "    # Iterate through the sorted list of items\n",
    "    for i in range(len(sorted_list)):\n",
    "        x: Item = sorted_list[i]  # Current item\n",
    "        coverage_list = list()  # Initialize coverage list for item x\n",
    "\n",
    "        # Iterate through the remaining items in the sorted list\n",
    "        for j in range(i + 1, len(sorted_list)):\n",
    "            y: Item = sorted_list[j]  # Potential pair for item x\n",
    "            xy: set[Item] = {x, y}\n",
    "            key = frozenset(xy)  # Key for the item pair\n",
    "            xy_twu = eucst_dict.get(key)  # Get TWU for the pair\n",
    "\n",
    "            # Check if the TWU matches item x's TWU\n",
    "            if x.twu == xy_twu:\n",
    "                coverage_list.append(y)\n",
    "\n",
    "        r = len(coverage_list)  # Size of the coverage list\n",
    "\n",
    "        # If no items are covered, append a placeholder\n",
    "        if r == 0:\n",
    "            coverage_list.append(-1)\n",
    "        else:\n",
    "            util: int = 0  # Initialize utility value\n",
    "\n",
    "            # Calculate utility for each covered pair\n",
    "            for z in range(0, r):\n",
    "                util += calculate_utility_of_item_set_in_database(\n",
    "                    {x, coverage_list[z]}, trans_dict\n",
    "                )\n",
    "\n",
    "            # Subtract overlap utility based on the coverage size\n",
    "            util -= (r - 1) * get_value_from_bin(x, utility_arr, item_index_dict)\n",
    "\n",
    "            # Append the computed utility to the COVL list\n",
    "            covl_list.append(util)\n",
    "\n",
    "    # Sort the COVL list in descending order\n",
    "    covl_list.sort(reverse=True)\n",
    "    return covl_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Algorithms**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.1 PHUIM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phui_searching_procedure(\n",
    "    PList: AbstractList,\n",
    "    lists: list[AbstractList],\n",
    "    current_min_util: int,\n",
    "    min_per_threshold: int,\n",
    "    max_per_threshold: int,\n",
    "    min_avg_threshold: int,\n",
    "    max_avg_threshold: int,\n",
    "    user_prob_threshold: float,\n",
    "    database: list[Transaction],\n",
    "    eucs_dict: dict[frozenset[Item], int],\n",
    "    item_transId_dict: dict[Item, list[int]],\n",
    "    k: int,\n",
    "    topk_queue: PriorityQueue,\n",
    "):\n",
    "    for i in range(len(lists)):\n",
    "        XList: AbstractList = lists[i]\n",
    "        XList_utility = XList.get_utility()\n",
    "        XList_prob = XList.get_pro()\n",
    "        XList_ru = XList.get_ru()\n",
    "        min_per, max_per, avg_per = find_min_max_avg_periodic_of_item_set(\n",
    "            XList.item_set, database, item_transId_dict\n",
    "        )\n",
    "        if (\n",
    "            XList_utility >= current_min_util\n",
    "            and round(XList_prob, 3) >= user_prob_threshold\n",
    "        ):\n",
    "            if (\n",
    "                min_per >= min_per_threshold\n",
    "                and max_per <= max_per_threshold\n",
    "                and avg_per >= min_avg_threshold\n",
    "                and avg_per <= max_avg_threshold\n",
    "            ):\n",
    "                topk_queue.push(\n",
    "                    XList_utility, XList.item_set, Periodic(min_per, max_per, avg_per)\n",
    "                )\n",
    "                if len(topk_queue.heap) == k:\n",
    "                    current_min_util = topk_queue.sort()[k - 1][0]\n",
    "\n",
    "        if (\n",
    "            max_per <= max_per_threshold\n",
    "            and avg_per <= max_avg_threshold\n",
    "            and XList_ru + XList_utility >= current_min_util\n",
    "            and round(XList_prob, 3) >= user_prob_threshold\n",
    "        ):\n",
    "            new_lists: list[AbstractList] = list()\n",
    "            for j in range(i + 1, len(lists)):\n",
    "                YList: PNUList = lists[j]\n",
    "                x = XList.item_set.difference(PList.item_set)\n",
    "                y = YList.item_set.difference(PList.item_set)\n",
    "                key = frozenset(x | y)\n",
    "                twu_value = eucs_dict.get(key, -1)\n",
    "                if twu_value >= current_min_util:\n",
    "                    ZList = utility_list_construct(\n",
    "                        PList, XList, YList, current_min_util, user_prob_threshold\n",
    "                    )\n",
    "                    if ZList:\n",
    "                        new_lists.append(ZList)\n",
    "            if new_lists:\n",
    "                phui_searching_procedure(\n",
    "                    XList,\n",
    "                    new_lists,\n",
    "                    current_min_util,\n",
    "                    min_per_threshold,\n",
    "                    max_per_threshold,\n",
    "                    min_avg_threshold,\n",
    "                    max_avg_threshold,\n",
    "                    user_prob_threshold,\n",
    "                    database,\n",
    "                    eucs_dict,\n",
    "                    item_transId_dict,\n",
    "                    k,\n",
    "                    topk_queue,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.2 PHUIM+**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phui_searching_procedure_plus(\n",
    "    PList: AbstractList,\n",
    "    lists: list[AbstractList],\n",
    "    current_min_util: int,\n",
    "    min_per_threshold: int,\n",
    "    max_per_threshold: int,\n",
    "    min_avg_threshold: int,\n",
    "    max_avg_threshold: int,\n",
    "    user_prob_threshold: float,\n",
    "    db: list[Transaction],\n",
    "    utility_array: list[int],\n",
    "    item_index_dict: dict[Item, int],\n",
    "    eucs_dict: dict[frozenset[Item], int],\n",
    "    item_transId_dict: dict[Item, list[int]],\n",
    "    k: int,\n",
    "    topk_queue: PriorityQueue,\n",
    ") -> None:\n",
    "    for i in range(len(lists)):\n",
    "        XList: AbstractList = lists[i]\n",
    "        x_utility = XList.get_utility()\n",
    "        x_prob = XList.get_pro()\n",
    "        x_ru = XList.get_ru()\n",
    "        min_per, max_per, avg_per = find_min_max_avg_periodic_of_item_set(\n",
    "            XList.item_set, db, item_transId_dict\n",
    "        )\n",
    "        if x_utility >= current_min_util and round(x_prob, 3) >= user_prob_threshold:\n",
    "            if (\n",
    "                min_per >= min_per_threshold\n",
    "                and max_per <= max_per_threshold\n",
    "                and avg_per >= min_avg_threshold\n",
    "                and avg_per <= max_avg_threshold\n",
    "            ):\n",
    "                topk_queue.push(\n",
    "                    x_utility, XList.item_set, Periodic(min_per, max_per, avg_per)\n",
    "                )\n",
    "                if len(topk_queue.heap) == k:\n",
    "                    current_min_util = topk_queue.sort()[k - 1][0]\n",
    "        if (\n",
    "            max_per <= max_per_threshold\n",
    "            and avg_per <= max_avg_threshold\n",
    "            and x_ru + x_utility >= current_min_util\n",
    "            and round(x_prob, 3) >= user_prob_threshold\n",
    "        ):\n",
    "            new_lists: list[AbstractList] = list()\n",
    "            for j in range(i + 1, len(lists)):\n",
    "                YList: AbstractList = lists[j]\n",
    "                x: set[Item] = XList.item_set.difference(PList.item_set)\n",
    "                y: set[Item] = YList.item_set.difference(PList.item_set)\n",
    "                twu_value: int = eucs_dict.get(frozenset(x | y), -1)\n",
    "                if twu_value >= current_min_util:\n",
    "                    du = calculate_dynamic_upper_bound(\n",
    "                        YList, XList, utility_array, item_index_dict\n",
    "                    )\n",
    "                    if du >= current_min_util:\n",
    "                        if isinstance(YList, MList):\n",
    "                            ZList: PNUList = utility_list_construct(\n",
    "                                YList.subset_prefix,\n",
    "                                XList,\n",
    "                                YList.subset,\n",
    "                                current_min_util,\n",
    "                                user_prob_threshold,\n",
    "                            )\n",
    "                            if ZList:\n",
    "                                new_lists.append(ZList)\n",
    "                        else:\n",
    "                            ZList: PNUList = utility_list_construct(\n",
    "                                PList,\n",
    "                                XList,\n",
    "                                YList,\n",
    "                                current_min_util,\n",
    "                                user_prob_threshold,\n",
    "                            )\n",
    "                            if ZList:\n",
    "                                new_lists.append(ZList)\n",
    "                    else:\n",
    "                        if isinstance(YList, MList):\n",
    "                            ZMlist: MList = mlist_construct_1(XList, YList, du)\n",
    "                            new_lists.append(ZMlist)\n",
    "                        else:\n",
    "                            ZMlist: MList = mlist_construct_2(XList, YList, PList, du)\n",
    "                            new_lists.append(ZMlist)\n",
    "            if new_lists:\n",
    "                phui_searching_procedure_plus(\n",
    "                    XList,\n",
    "                    new_lists,\n",
    "                    current_min_util,\n",
    "                    min_per_threshold,\n",
    "                    max_per_threshold,\n",
    "                    min_avg_threshold,\n",
    "                    max_avg_threshold,\n",
    "                    user_prob_threshold,\n",
    "                    db,\n",
    "                    utility_array,\n",
    "                    item_index_dict,\n",
    "                    eucs_dict,\n",
    "                    item_transId_dict,\n",
    "                    k,\n",
    "                    topk_queue,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_mining_based_on_PHUI(\n",
    "    database: list[Transaction],\n",
    "    item_list: list[Item],\n",
    "    k: int,\n",
    "    min_per_threshold: int,\n",
    "    max_per_threshold: int,\n",
    "    min_avg_threshold: int,\n",
    "    max_avg_threshold: int,\n",
    "    min_prob: float,\n",
    "    is_plus: bool,\n",
    ") -> PriorityQueue:\n",
    "    # Create priority to contains top-k HUI\n",
    "    topk_queue = PriorityQueue(k)\n",
    "    user_prob_threshold = round(min_prob * len(database), 3)\n",
    "\n",
    "    # Create a utility array & and a dictionary to search\n",
    "    prob_arr, twu_arr, utility_arr, item_index_dict = create_prob_twu_utility_bin_array(\n",
    "        item_list, database\n",
    "    )\n",
    "    positive_utility_arr = [u for u in utility_arr if u > 0]\n",
    "    # First update min_util = the k-th highest utility value (using RIU strategy)\n",
    "    current_min_util: int = priu_pruning(positive_utility_arr, k)\n",
    "\n",
    "    # Create a list that contains all items is unqualified\n",
    "    removed_list: set[Item] = set()\n",
    "\n",
    "    # Create a diction contains item: list[transaction_id]\n",
    "    item_transId_dict: dict[Item, list[int]] = create_item_transId_dict(\n",
    "        item_list, database\n",
    "    )\n",
    "    for i in range(len(item_list)):\n",
    "        _, max_per, avg_per = find_min_max_avg_periodic_of_item_set(\n",
    "            {item_list[i]}, database, item_transId_dict\n",
    "        )\n",
    "        if (\n",
    "            max_per <= max_per_threshold\n",
    "            and avg_per <= max_avg_threshold\n",
    "            and twu_arr[i] >= current_min_util\n",
    "            and round(prob_arr[i], 3) >= user_prob_threshold\n",
    "        ):\n",
    "            item_list[i].twu = twu_arr[i]\n",
    "        else:\n",
    "            removed_list.add(item_list[i])\n",
    "    # Remove unqualified item\n",
    "    new_distinct_items = [item for item in item_list if item not in removed_list]\n",
    "    # Sort item list by order\n",
    "    new_distinct_items = sort_items_by_twu_and_utility(new_distinct_items)\n",
    "\n",
    "    # Remove unqualified items from transaction\n",
    "    for trans in database:\n",
    "        for item in removed_list:\n",
    "            trans.trans_items_dict.pop(item, None)\n",
    "            try:\n",
    "                trans.trans_items_list.remove(item)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        trans.sort_trans_items_by_twu_and_utility()\n",
    "\n",
    "    # Convert database - list[Transaction] into dict[Item, set[Transaction]]\n",
    "    trans_dict: dict[Item, set[Transaction]] = create_transaction_dictionary(\n",
    "        new_distinct_items, database\n",
    "    )\n",
    "    # Create list[AbstractList],\n",
    "    pnu_lists: list[PNUList] = create_pnu_lists(trans_dict)\n",
    "\n",
    "    # Create EUCST dict that contain twu > current_min_util of all 2-item-set\n",
    "    eucst_dict: dict[frozenset[Item], int] = create_eucst_dict(\n",
    "        new_distinct_items, database, trans_dict, current_min_util\n",
    "    )\n",
    "\n",
    "    # Create CUDM dict that contain utility of all 2-item-set\n",
    "    cudm_dict: dict[frozenset[Item], int] = create_liu_dict(\n",
    "        new_distinct_items, trans_dict\n",
    "    )\n",
    "\n",
    "    # Update and increase current_min_util\n",
    "    if cudm_dict:\n",
    "        cud: int = pliue_strategy(cudm_dict, k, current_min_util)\n",
    "        # Update current min_util = the k-th highest utility in CUDM dict\n",
    "        current_min_util = max(current_min_util, cud)\n",
    "\n",
    "    covl: list[int] = covl_construct(\n",
    "        new_distinct_items, eucst_dict, utility_arr, item_index_dict, trans_dict\n",
    "    )\n",
    "    # Update and increase current_min_util\n",
    "    if covl:\n",
    "        current_min_util = max(current_min_util, covl[min(len(covl), k) - 1])\n",
    "    eucst_dict: dict[frozenset, int] = update_eucst_dict(eucst_dict, current_min_util)\n",
    "    root = PNUList({}, list())\n",
    "    if is_plus:\n",
    "        phui_searching_procedure_plus(\n",
    "            root,\n",
    "            pnu_lists,\n",
    "            current_min_util,\n",
    "            min_per_threshold,\n",
    "            max_per_threshold,\n",
    "            min_avg_threshold,\n",
    "            max_avg_threshold,\n",
    "            user_prob_threshold,\n",
    "            database,\n",
    "            utility_arr,\n",
    "            item_index_dict,\n",
    "            eucst_dict,\n",
    "            item_transId_dict,\n",
    "            k,\n",
    "            topk_queue,\n",
    "        )\n",
    "    else:\n",
    "        phui_searching_procedure(\n",
    "            root,\n",
    "            pnu_lists,\n",
    "            current_min_util,\n",
    "            min_per_threshold,\n",
    "            max_per_threshold,\n",
    "            min_avg_threshold,\n",
    "            max_avg_threshold,\n",
    "            user_prob_threshold,\n",
    "            database,\n",
    "            eucst_dict,\n",
    "            item_transId_dict,\n",
    "            k,\n",
    "            topk_queue,\n",
    "        )\n",
    "    return topk_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.3 EFIM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efim_global_search(\n",
    "    alpha: set[Item],\n",
    "    primary: list[Item],\n",
    "    secondary: list[Item],\n",
    "    min_util: int,\n",
    "    min_per_threshold: int,\n",
    "    max_per_threshold: int,\n",
    "    min_avg_threshold: int,\n",
    "    max_avg_threshold: int,\n",
    "    user_prob_threshold: float,\n",
    "    k: int,\n",
    "    item_dict: dict[Item, int],\n",
    "    topk_queue: PriorityQueue,\n",
    "    trans_dict: dict[Item, set[Transaction]],\n",
    "    item_transId_dict: dict[Item, list[int]],\n",
    "    database: list[Transaction],\n",
    ") -> None:\n",
    "    for pri_item in primary:\n",
    "        beta: set[Item] = alpha | {pri_item}\n",
    "        prob, util, ru = calculate_probability_and_utility_of_item_set_in_database(\n",
    "            beta, trans_dict\n",
    "        )\n",
    "        min_per, max_per, avg_per = find_min_max_avg_periodic_of_item_set(\n",
    "            beta, database, item_transId_dict\n",
    "        )\n",
    "        if util >= min_util and round(prob, 3) >= user_prob_threshold:\n",
    "            if (\n",
    "                min_per >= min_per_threshold\n",
    "                and max_per <= max_per_threshold\n",
    "                and avg_per >= min_avg_threshold\n",
    "                and avg_per <= max_avg_threshold\n",
    "            ):\n",
    "                topk_queue.push(util, beta, Periodic(min_per, max_per, avg_per))\n",
    "                if len(topk_queue.heap) == k:\n",
    "                    min_util = topk_queue.sort()[k - 1][0]\n",
    "        if (\n",
    "            max_per <= max_per_threshold\n",
    "            and avg_per <= max_avg_threshold\n",
    "            and ru + util >= min_util\n",
    "            and round(prob, 3) >= user_prob_threshold\n",
    "        ):\n",
    "            i = secondary.index(pri_item)\n",
    "            if i != -1 and i + 1 < len(secondary):\n",
    "                second_item = secondary[i + 1]\n",
    "                if (\n",
    "                    util < min_util\n",
    "                    or round(prob, 3) < user_prob_threshold\n",
    "                    or min_per < min_per_threshold\n",
    "                    or max_per > max_per_threshold\n",
    "                    or avg_per < min_avg_threshold\n",
    "                    or avg_per > max_avg_threshold\n",
    "                ) and second_item.utility < 0:\n",
    "                    continue\n",
    "\n",
    "            beta_dp: set[Transaction] = create_database_projection(beta, trans_dict)\n",
    "            lu_arr = create_local_utility_bin_array(beta, secondary, beta_dp)\n",
    "            new_primary: list[Item] = list()\n",
    "            new_secondary: list[Item] = list()\n",
    "            for j in range(i + 1, len(secondary)):\n",
    "                if lu_arr[j] >= min_util:\n",
    "                    new_secondary.append(secondary[j])\n",
    "\n",
    "            su_arr = create_subtree_utility_bin_array(beta, new_secondary, beta_dp)\n",
    "            for j in range(len(new_secondary)):\n",
    "                if su_arr[j] >= min_util:\n",
    "                    new_primary.append(new_secondary[j])\n",
    "            if new_primary and new_secondary:\n",
    "                efim_global_search(\n",
    "                    beta,\n",
    "                    new_primary,\n",
    "                    new_secondary,\n",
    "                    min_util,\n",
    "                    min_per_threshold,\n",
    "                    max_per_threshold,\n",
    "                    min_avg_threshold,\n",
    "                    max_avg_threshold,\n",
    "                    user_prob_threshold,\n",
    "                    k,\n",
    "                    item_dict,\n",
    "                    topk_queue,\n",
    "                    trans_dict,\n",
    "                    item_transId_dict,\n",
    "                    database,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_mining_based_on_EFIM(\n",
    "    database: list[Transaction],\n",
    "    item_list: list[Item],\n",
    "    k: int,\n",
    "    min_per_threshold: int,\n",
    "    max_per_threshold: int,\n",
    "    min_avg_threshold: int,\n",
    "    max_avg_threshold: int,\n",
    "    min_prob: float,\n",
    ") -> PriorityQueue:\n",
    "    if k <= 0:\n",
    "        return\n",
    "    # Init alpha with empty set\n",
    "    alpha: set[Item] = set()\n",
    "    topk_queue = PriorityQueue(k)\n",
    "    current_min_util = 0\n",
    "    user_prob_threshold = min_prob * len(database)\n",
    "\n",
    "    prob_arr, twu_arr, utility_arr, item_dict = create_prob_twu_utility_bin_array(\n",
    "        item_list, database\n",
    "    )\n",
    "    # Get only positive item set\n",
    "    positive_utility_list: list[Item] = [\n",
    "        utility for utility in utility_arr if utility > 0\n",
    "    ]\n",
    "\n",
    "    # Update current_min_util = the k-th largest in utility array\n",
    "    current_min_util: int = priu_pruning(positive_utility_list, k)\n",
    "\n",
    "    # Create secondary list\n",
    "    secondary = list()\n",
    "\n",
    "    item_transId_dict: dict[Item, list[int]] = create_item_transId_dict(\n",
    "        item_list, database\n",
    "    )\n",
    "\n",
    "    for i in range(len(item_list)):\n",
    "        if round(prob_arr[i], 3) >= user_prob_threshold and twu_arr[i] >= current_min_util:\n",
    "            _, max_per, avg_per = find_min_max_avg_periodic_of_item_set(\n",
    "                {item_list[i]}, database, item_transId_dict\n",
    "            )\n",
    "            if max_per <= max_per_threshold and avg_per <= max_avg_threshold:\n",
    "                item_list[i].twu = twu_arr[i]\n",
    "                secondary.append(item_list[i])\n",
    "\n",
    "    # Create removed_list contains item unqualified\n",
    "    removed_list = set(item_list).difference(secondary)\n",
    "\n",
    "    # Remove those items in removed_list from database\n",
    "    for trans in database:\n",
    "        for item in removed_list:\n",
    "            trans.trans_items_dict.pop(item, None)\n",
    "            try:\n",
    "                trans.trans_items_list.remove(item)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        trans.sort_trans_items_by_twu_and_utility()\n",
    "\n",
    "    # Convert database (list[Transaction]) to trans_dict (dict[Item, set[Transaction]])\n",
    "    trans_dict: dict[Item, set[Transaction]] = create_transaction_dictionary(\n",
    "        secondary, database\n",
    "    )\n",
    "    # Create liu dict, to update current_min_util\n",
    "    lius: dict[frozenset[Item], int] = create_liu_dict(secondary, trans_dict)\n",
    "    if lius:\n",
    "        current_min_util = pliue_strategy(lius, k, current_min_util)\n",
    "\n",
    "    secondary = sort_items_by_twu_and_utility(secondary)\n",
    "\n",
    "    eucst_dict: dict[frozenset[Item], int] = create_eucst_dict(\n",
    "        secondary, database, trans_dict, current_min_util\n",
    "    )\n",
    "    covl: list[int] = covl_construct(\n",
    "        secondary, eucst_dict, utility_arr, item_dict, trans_dict\n",
    "    )\n",
    "    # Update and increase current_min_util\n",
    "    if covl:\n",
    "        current_min_util = max(current_min_util, covl[min(len(covl), k) - 1])\n",
    "\n",
    "    # Create primary & secondary list\n",
    "    primary: list[Item] = [\n",
    "        secondary[i]\n",
    "        for i in range(len(secondary))\n",
    "        if calculate_subtree_utility(alpha, secondary[i], set(database), trans_dict)\n",
    "        >= current_min_util\n",
    "    ]\n",
    "\n",
    "    efim_global_search(\n",
    "        alpha,\n",
    "        primary,\n",
    "        secondary,\n",
    "        current_min_util,\n",
    "        min_per_threshold,\n",
    "        max_per_threshold,\n",
    "        min_avg_threshold,\n",
    "        max_avg_threshold,\n",
    "        user_prob_threshold,\n",
    "        k,\n",
    "        item_dict,\n",
    "        topk_queue,\n",
    "        trans_dict,\n",
    "        item_transId_dict,\n",
    "        database,\n",
    "    )\n",
    "\n",
    "    return topk_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Testing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Item(\"a\", 6)\n",
    "# b = Item(\"b\", 7)\n",
    "# c = Item(\"c\", 1)\n",
    "# d = Item(\"d\", -5)\n",
    "# e = Item(\"e\", 3)\n",
    "\n",
    "# t1_trans_items = {TransItem(b, 3, 0.85), TransItem(c, 1, 1.0), TransItem(d, 2, 0.70)}\n",
    "\n",
    "# t2_trans_items = {\n",
    "#     TransItem(a, 1, 1.0),\n",
    "#     TransItem(b, 1, 0.60),\n",
    "#     TransItem(c, 3, 0.75),\n",
    "#     TransItem(e, 1, 0.40),\n",
    "# }\n",
    "\n",
    "# t3_trans_items = {\n",
    "#     TransItem(a, 1, 0.55),\n",
    "#     TransItem(b, 2, 0.60),\n",
    "#     TransItem(c, 4, 1.0),\n",
    "#     TransItem(d, 1, 0.90),\n",
    "#     TransItem(e, 5, 0.40),\n",
    "# }\n",
    "\n",
    "# t4_trans_items = {TransItem(b, 3, 0.90), TransItem(d, 1, 0.45)}\n",
    "\n",
    "# t5_trans_items = {\n",
    "#     TransItem(a, 4, 1.0),\n",
    "#     TransItem(c, 3, 0.85),\n",
    "#     TransItem(d, 2, 0.70),\n",
    "#     TransItem(e, 2, 0.45),\n",
    "# }\n",
    "\n",
    "# t1 = Transaction(1, t1_trans_items)\n",
    "# t2 = Transaction(2, t2_trans_items)\n",
    "# t3 = Transaction(3, t3_trans_items)\n",
    "# t4 = Transaction(4, t4_trans_items)\n",
    "# t5 = Transaction(5, t5_trans_items)\n",
    "\n",
    "# item_list = [a, b, c, d, e]\n",
    "# db1 = [t1, t2, t3, t4, t5]\n",
    "# db2 = [t1, t2, t3, t4, t5]\n",
    "# db3 = [t1, t2, t3, t4, t5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Item(\"a\", 3)\n",
    "b = Item(\"b\", 6)\n",
    "c = Item(\"c\", -3)\n",
    "d = Item(\"d\", 12)\n",
    "e = Item(\"e\", -5)\n",
    "f = Item(\"f\", -2)\n",
    "g = Item(\"g\", -1)\n",
    "\n",
    "t1_trans_items = [\n",
    "    TransItem(a, 5, 0.0),\n",
    "    TransItem(b, 2, 0.0),\n",
    "    TransItem(c, 1, 0.0),\n",
    "    TransItem(d, 2, 0.0),\n",
    "]\n",
    "\n",
    "t2_trans_items = [\n",
    "    TransItem(a, 1, 0.0),\n",
    "    TransItem(c, 1, 0.0),\n",
    "    TransItem(d, 1, 0.0),\n",
    "    TransItem(g, 3, 0.0),\n",
    "]\n",
    "\n",
    "t3_trans_items = [\n",
    "    TransItem(a, 1, 0.0),\n",
    "    TransItem(c, 1, 0.0),\n",
    "    TransItem(f, 1, 0.0),\n",
    "]\n",
    "\n",
    "t4_trans_items = [TransItem(a, 1, 0.0), TransItem(f, 4, 0.0), TransItem(g, 2, 0.0)]\n",
    "\n",
    "t5_trans_items = [\n",
    "    TransItem(a, 1, 0.0),\n",
    "    TransItem(g, 2, 0.0),\n",
    "]\n",
    "\n",
    "t6_trans_items = [\n",
    "    TransItem(b, 3, 0.0),\n",
    "    TransItem(c, 2, 0.0),\n",
    "    TransItem(d, 3, 0.0),\n",
    "    TransItem(e, 1, 0.0),\n",
    "]\n",
    "\n",
    "t7_trans_items = [\n",
    "    TransItem(c, 6, 0.0),\n",
    "    TransItem(e, 4, 0.0),\n",
    "]\n",
    "t8_trans_items = [\n",
    "    TransItem(e, 1, 0.0),\n",
    "    TransItem(f, 3, 0.0),\n",
    "]\n",
    "t1 = Transaction(1, t1_trans_items)\n",
    "t2 = Transaction(2, t2_trans_items)\n",
    "t3 = Transaction(3, t3_trans_items)\n",
    "t4 = Transaction(4, t4_trans_items)\n",
    "t5 = Transaction(5, t5_trans_items)\n",
    "t6 = Transaction(6, t6_trans_items)\n",
    "t7 = Transaction(7, t7_trans_items)\n",
    "t8 = Transaction(8, t8_trans_items)\n",
    "\n",
    "item_list_1 = list([a, b, c, d, e, f, g])\n",
    "item_list_2 = list([a, b, c, d, e, f, g])\n",
    "item_list_3 = list([a, b, c, d, e, f, g])\n",
    "db1 = list([t1, t2, t3, t4, t5, t6, t7, t8])\n",
    "db2 = list([t1, t2, t3, t4, t5, t6, t7, t8])\n",
    "db3 = list([t1, t2, t3, t4, t5, t6, t7, t8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75, 90, 39, 72, -30, -16, -7]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_subtree_utility_bin_array(set(), item_list_1, db1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(file_path: str, data: list[tuple], total_time: datetime, append: bool = False):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    mode = \"a\" if append else \"w\"\n",
    "    with open(file_path, mode) as file:\n",
    "        file.write(str(datetime.datetime.now()) + \"\\n\")\n",
    "        for utility, item_set, periodic in data:\n",
    "            formatted_periodic = f\"(min_per={periodic.min_per}, max_per={periodic.max_per}, avg_per={periodic.avg_per:.2f})\"\n",
    "            file.write(f\"{item_set} : {utility} : {formatted_periodic}\\n\")\n",
    "        file.write(\"Take total time: \" + str(total_time) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "prob_threshold = 0.0\n",
    "min_per_threshold = 1\n",
    "max_per_threshold = 5\n",
    "min_avg_threshold = 1\n",
    "max_avg_threshold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{d, b} : 90 : (min_per=1, max_per=5, avg_per=2.67)\n",
      "{d, c, b} : 81 : (min_per=1, max_per=5, avg_per=2.67)\n",
      "{d} : 72 : (min_per=1, max_per=4, avg_per=2.00)\n",
      "{c, d} : 60 : (min_per=1, max_per=4, avg_per=2.00)\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.datetime.now()\n",
    "rs1 = topk_mining_based_on_PHUI(\n",
    "    db1,\n",
    "    item_list_1,\n",
    "    k,\n",
    "    min_per_threshold,\n",
    "    max_per_threshold,\n",
    "    min_avg_threshold,\n",
    "    max_avg_threshold,\n",
    "    prob_threshold,\n",
    "    False,\n",
    ")\n",
    "t2 = datetime.datetime.now()\n",
    "rs1.print_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{d, b} : 90 : (min_per=1, max_per=5, avg_per=2.67)\n",
      "{d, c, b} : 81 : (min_per=1, max_per=5, avg_per=2.67)\n",
      "{d} : 72 : (min_per=1, max_per=4, avg_per=2.00)\n",
      "{c, d} : 60 : (min_per=1, max_per=4, avg_per=2.00)\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.datetime.now()\n",
    "rs2 = topk_mining_based_on_PHUI(\n",
    "    db2,\n",
    "    item_list_2,\n",
    "    k,\n",
    "    min_per_threshold,\n",
    "    max_per_threshold,\n",
    "    min_avg_threshold,\n",
    "    max_avg_threshold,\n",
    "    prob_threshold,\n",
    "    True,\n",
    ")\n",
    "t2 = datetime.datetime.now()\n",
    "rs2.print_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{d, b} : 90 : (min_per=1, max_per=5, avg_per=2.67)\n",
      "{d, c, b} : 81 : (min_per=1, max_per=5, avg_per=2.67)\n",
      "{d} : 72 : (min_per=1, max_per=4, avg_per=2.00)\n",
      "{c, d} : 60 : (min_per=1, max_per=4, avg_per=2.00)\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.datetime.now()\n",
    "rs3 = topk_mining_based_on_EFIM(\n",
    "    db3,\n",
    "    item_list_3,\n",
    "    k,\n",
    "    min_per_threshold,\n",
    "    max_per_threshold,\n",
    "    min_avg_threshold,\n",
    "    max_avg_threshold,\n",
    "    prob_threshold,\n",
    ")\n",
    "t2 = datetime.datetime.now()\n",
    "rs3.print_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_list1 = [Item(f\"i{i+1}\", random.randint(-10, 10)) for i in range(30)]\n",
    "# item_list2 = list(item_list1)\n",
    "# item_list3 = list(item_list1)\n",
    "# db1 = list()\n",
    "# db2 = list()\n",
    "# db3 = list()\n",
    "# for transaction_id in range(1, 1001):\n",
    "#     trans_items = list()\n",
    "#     selected_items = random.sample(item_list1, random.randint(15, 25))\n",
    "#     for item in selected_items:\n",
    "#         quantity = random.randint(1, 10)\n",
    "#         probability = round(random.uniform(0.30, 0.99), 2)\n",
    "#         trans_item = TransItem(item, quantity, probability)\n",
    "#         trans_items.append(trans_item)\n",
    "#     transaction = Transaction(transaction_id, trans_items)\n",
    "#     db1.append(transaction)\n",
    "#     db2.append(transaction)\n",
    "#     db3.append(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 10\n",
    "# prob_threshold = 0.0001\n",
    "# min_per_threshold = 1\n",
    "# max_per_threshold = 1000\n",
    "# min_avg_threshold = 1\n",
    "# max_avg_threshold = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs1 = topk_mining_based_on_PHUI(\n",
    "#     db1,\n",
    "#     item_list1,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "#     False,\n",
    "# )\n",
    "# rs1.print_items()\n",
    "# t2 = datetime.datetime.now()\n",
    "# print(\"topk_mining_based_on_PHUI(false): \" + str(len(rs1.heap)))\n",
    "# print(\"topk_mining_based_on_PHUI(false): \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs2 = topk_mining_based_on_PHUI(\n",
    "#     db2,\n",
    "#     item_list2,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "#     True,\n",
    "# )\n",
    "# rs2.print_items()\n",
    "# t2 = datetime.datetime.now()\n",
    "# print(\"topk_mining_based_on_PHUI(true): \" + str(len(rs2.heap)))\n",
    "# print(\"topk_mining_based_on_PHUI(true): \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs3 = topk_mining_based_on_EFIM(\n",
    "#     db3,\n",
    "#     item_list3,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "# )\n",
    "# rs3.print_items()\n",
    "# t2 = datetime.datetime.now()\n",
    "# print(\"topk_mining_based_on_EFIM: \" + str(len(rs3.heap)))\n",
    "# print(\"topk_mining_based_on_EFIM: \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Experiments and Evaluation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_item_by_name(name: str, item_set: set[Item]) -> Item:\n",
    "    for item in item_set:\n",
    "        if item.item == name:\n",
    "            return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_trans_to_string(trans: Transaction) -> str:\n",
    "    items = \" \".join(map(str, trans.trans_items_list))\n",
    "    probabilities = \" \".join(\n",
    "        f\"{prob:.2f}\" for _, prob in trans.trans_items_dict.values()\n",
    "    )\n",
    "    quantities = \" \".join(map(str, (qty for qty, _ in trans.trans_items_dict.values())))\n",
    "    result = f\"{items}:{probabilities}:{quantities}\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_item_file(item_file_path: str):\n",
    "    item_set: set[Item] = set()\n",
    "    try:\n",
    "        with open(item_file_path) as file:\n",
    "            for line in file:\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                arr = line.split(\" \")\n",
    "                item: Item = Item(arr[0], int(arr[1]))\n",
    "                item_set.add(item)\n",
    "        return item_set\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"The file at {item_file_path} does not exist.\")\n",
    "    except IOError as e:\n",
    "        raise IOError(f\"An error occurred while reading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transaction_data(trans_file_path: str, item_set: set[Item], num_line: int):\n",
    "    database: list[Transaction] = list()\n",
    "    try:\n",
    "        with open(trans_file_path) as file:\n",
    "            tid = 1\n",
    "            for line in file:\n",
    "                line: str = line.replace(\"\\n\", \"\")\n",
    "                arr: list[str] = line.split(\":\")\n",
    "                item_list: list[str] = arr[0].split(\" \")\n",
    "                prob_list: list[str] = arr[1].split(\" \")\n",
    "                quantity_list: list[str] = arr[2].split(\" \")\n",
    "                trans_item_list = list()\n",
    "                for i in range(len(item_list)):\n",
    "                    item_name = item_list[i]\n",
    "                    item_obj = find_item_by_name(item_name, item_set)\n",
    "                    transItem = TransItem(item_obj, int(quantity_list[i]), float(prob_list[i]))\n",
    "                    trans_item_list.append(transItem)\n",
    "                trans = Transaction(tid, trans_item_list)\n",
    "                database.append(trans)\n",
    "                tid += 1\n",
    "                if tid > num_line:\n",
    "                    break\n",
    "        return database\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"The file at {trans_file_path} does not exist.\")\n",
    "    except IOError as e:\n",
    "        raise IOError(f\"An error occurred while reading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_item_to_file(file_path: str, data: list[str], append: bool = False):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    mode = \"a\" if append else \"w\"\n",
    "    with open(file_path, mode) as file:\n",
    "        for s in data:\n",
    "            file.write(f\"{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_aggregate_data(\n",
    "    file_path: str, lines: int\n",
    ") -> tuple[list[Item], list[Transaction]]:\n",
    "    item_set: set[Item] = set()\n",
    "    item_set_name: set[str] = set()\n",
    "    trans_item: list[TransItem] = list()\n",
    "    database: list[Transaction] = list()\n",
    "    try:\n",
    "        with open(file_path) as file:\n",
    "            tid: int = 1\n",
    "            for line in file:\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                arr = line.split(\":\")\n",
    "                left_arr = arr[0].split(\" \")\n",
    "                right_arr = arr[2].split(\" \")\n",
    "                for i in left_arr:\n",
    "                    if i not in item_set_name:\n",
    "                        item_set_name.add(i)\n",
    "                        item: Item = Item(i, random.randint(-10, 10))\n",
    "                        item_set.add(item)\n",
    "                trans_item_list = list()\n",
    "                for i in range(len(left_arr)):\n",
    "                    item_name: str = left_arr[i]\n",
    "                    item: Item = find_item_by_name(item_name, item_set)\n",
    "                    trans_item: TransItem = TransItem(\n",
    "                        item, int(right_arr[i]), round(random.uniform(0.01, 0.99), 2)\n",
    "                    )\n",
    "                    trans_item_list.append(trans_item)\n",
    "                trans = Transaction(tid, trans_item_list)\n",
    "                database.append(trans)\n",
    "                tid += 1\n",
    "                if(tid > lines):\n",
    "                    return list(item_set), database\n",
    "        return list(item_set), database\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"The file at {file_path} does not exist.\")\n",
    "    except IOError as e:\n",
    "        raise IOError(f\"An error occurred while reading the file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itemset, database = read_aggregate_data(\"dataset/ecommerce/ecommerce_dataset.txt\", 100000)\n",
    "# trans_data = list()\n",
    "# item_data = list()\n",
    "# for trans in database:\n",
    "#     s = convert_trans_to_string(trans)\n",
    "#     trans_data.append(s)\n",
    "# for item in itemset:\n",
    "#     item_data.append(str(item.item) + \" \" + str(item.utility))\n",
    "# write_item_to_file(\"dataset/ecommerce/items.txt\", item_data)\n",
    "# write_item_to_file(\"dataset/ecommerce/transactions.txt\", trans_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_list = read_item_file(\"dataset/accident/items.txt\")\n",
    "# database = read_transaction_data(\"dataset/accident/transactions.txt\", item_list, 1000)\n",
    "# item_list_1, database_1 = list(item_list), list(database)\n",
    "# item_list_2, database_2 = list(item_list_1), list(database_1)\n",
    "# item_list_3, database_3 = list(item_list_1), list(database_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 10\n",
    "# prob_threshold = 0.002\n",
    "# min_per_threshold = 1\n",
    "# max_per_threshold = 3000\n",
    "# min_avg_threshold = 1\n",
    "# max_avg_threshold = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs1 = topk_mining_based_on_PHUI(\n",
    "#     database_1,\n",
    "#     item_list_1,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "#     False,\n",
    "# )\n",
    "# t2 = datetime.datetime.now()\n",
    "# rs1.print_items()\n",
    "# write_to_file(\"output/accident/false.txt\", rs1.sort(), str(t2 - t1))\n",
    "# print(\"topk_mining_based_on_PHUI(false): \" + str(len(rs1.heap)))\n",
    "# print(\"topk_mining_based_on_PHUI(false): \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs2 = topk_mining_based_on_PHUI(\n",
    "#     database_2,\n",
    "#     item_list_2,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "#     True,\n",
    "# )\n",
    "# t2 = datetime.datetime.now()\n",
    "# rs2.print_items()\n",
    "# write_to_file(\"output/accident/true.txt\", rs2.sort(), str(t2 - t1))\n",
    "# print(\"topk_mining_based_on_PHUI(true): \" + str(len(rs2.heap)))\n",
    "# print(\"topk_mining_based_on_PHUI(true): \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs3 = topk_mining_based_on_EFIM(\n",
    "#     database_3,\n",
    "#     item_list_3,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "# )\n",
    "# t2 = datetime.datetime.now()\n",
    "# rs3.print_items()\n",
    "# write_to_file(\"output/accident/efim.txt\", rs3.sort(), str(t2 - t1))\n",
    "# print(\"topk_mining_based_on_EFIM: \" + str(len(rs3.heap)))\n",
    "# print(\"topk_mining_based_on_EFIM: \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accident_dataset():\n",
    "    # Parameters for each dataset size\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"n\": 1000,\n",
    "            \"k\": 10,\n",
    "            \"prob_threshold\": 0.002,\n",
    "            \"min_per_threshold\": 1,\n",
    "            \"max_per_threshold\": 100,\n",
    "            \"min_avg_threshold\": 1,\n",
    "            \"max_avg_threshold\": 100,\n",
    "        },\n",
    "        {\n",
    "            \"n\": 5000,\n",
    "            \"k\": 10,\n",
    "            \"prob_threshold\": 0.002,\n",
    "            \"min_per_threshold\": 1,\n",
    "            \"max_per_threshold\": 100,\n",
    "            \"min_avg_threshold\": 1,\n",
    "            \"max_avg_threshold\": 100,\n",
    "        },\n",
    "        # {\n",
    "        #     \"n\": 10000,\n",
    "        #     \"k\": 10,\n",
    "        #     \"prob_threshold\": 0.001,\n",
    "        #     \"min_per_threshold\": 1,\n",
    "        #     \"max_per_threshold\": 200,\n",
    "        #     \"min_avg_threshold\": 1,\n",
    "        #     \"max_avg_threshold\": 200,\n",
    "        # },\n",
    "        # {\n",
    "        #     \"n\": 20000,\n",
    "        #     \"k\": 10,\n",
    "        #     \"prob_threshold\": 0.001,\n",
    "        #     \"min_per_threshold\": 1,\n",
    "        #     \"max_per_threshold\": 200,\n",
    "        #     \"min_avg_threshold\": 1,\n",
    "        #     \"max_avg_threshold\": 200,\n",
    "        # },\n",
    "    ]\n",
    "\n",
    "    # Time results\n",
    "    results_phui_false = []\n",
    "    results_phui_true = []\n",
    "    results_efim = []\n",
    "\n",
    "    # Run experiments for each test case\n",
    "    for case in test_cases:\n",
    "        n = int(case[\"n\"])\n",
    "        k = int(case[\"k\"])\n",
    "        prob_threshold = float(case[\"prob_threshold\"])\n",
    "        min_per_threshold = int(case[\"min_per_threshold\"])\n",
    "        max_per_threshold = int(case[\"max_per_threshold\"])\n",
    "        min_avg_threshold = int(case[\"min_avg_threshold\"])\n",
    "        max_avg_threshold = int(case[\"max_avg_threshold\"])\n",
    "\n",
    "        # Generate dataset\n",
    "        item_list_1 = list(read_item_file(\"dataset/accident/items.txt\"))\n",
    "        item_list_2 = list(read_item_file(\"dataset/accident/items.txt\"))\n",
    "        item_list_3 = list(read_item_file(\"dataset/accident/items.txt\"))\n",
    "\n",
    "        database_1 = read_transaction_data(\n",
    "            \"dataset/accident/transactions.txt\", item_list_1, n\n",
    "        )\n",
    "        database_2 = read_transaction_data(\n",
    "            \"dataset/accident/transactions.txt\", item_list_2, n\n",
    "        )\n",
    "        database_3 = read_transaction_data(\n",
    "            \"dataset/accident/transactions.txt\", item_list_3, n\n",
    "        )\n",
    "\n",
    "        # Measure time for Algorithm 1\n",
    "        start_time = time.time()\n",
    "        rs1 = topk_mining_based_on_PHUI(\n",
    "            database_1,\n",
    "            item_list_1,\n",
    "            k,\n",
    "            min_per_threshold,\n",
    "            max_per_threshold,\n",
    "            min_avg_threshold,\n",
    "            max_avg_threshold,\n",
    "            prob_threshold,\n",
    "            False,\n",
    "        )\n",
    "        results_phui_false.append(time.time() - start_time)\n",
    "        write_to_file(\n",
    "            \"output2/accident/false.txt\",\n",
    "            rs1.sort(),\n",
    "            str(time.time() - start_time),\n",
    "            True,\n",
    "        )\n",
    "        # Measure time for Algorithm 2\n",
    "        start_time = time.time()\n",
    "        rs2 = topk_mining_based_on_PHUI(\n",
    "            database_2,\n",
    "            item_list_2,\n",
    "            k,\n",
    "            min_per_threshold,\n",
    "            max_per_threshold,\n",
    "            min_avg_threshold,\n",
    "            max_avg_threshold,\n",
    "            prob_threshold,\n",
    "            True,\n",
    "        )\n",
    "        results_phui_true.append(time.time() - start_time)\n",
    "        write_to_file(\n",
    "            \"output2/accident/true.txt\", rs2.sort(), str(time.time() - start_time), True\n",
    "        )\n",
    "        # Measure time for Algorithm 3\n",
    "        start_time = time.time()\n",
    "        rs3 = topk_mining_based_on_EFIM(\n",
    "            database_3,\n",
    "            item_list_3,\n",
    "            k,\n",
    "            min_per_threshold,\n",
    "            max_per_threshold,\n",
    "            min_avg_threshold,\n",
    "            max_avg_threshold,\n",
    "            prob_threshold,\n",
    "        )\n",
    "        results_efim.append(time.time() - start_time)\n",
    "        write_to_file(\n",
    "            \"output2/accident/efim1.txt\", rs3.sort(), str(time.time() - start_time), True\n",
    "        )\n",
    "    # Extract dataset sizes\n",
    "    dataset_sizes = [case[\"n\"] for case in test_cases]\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(dataset_sizes, results_phui_false, label=\"PHUI (Flag=False)\", marker=\"o\")\n",
    "    plt.plot(dataset_sizes, results_phui_true, label=\"PHUI (Flag=True)\", marker=\"o\")\n",
    "    plt.plot(dataset_sizes, results_efim, label=\"EFIM\", marker=\"o\")\n",
    "\n",
    "    plt.title(\"Execution Time Comparison of Algorithms\")\n",
    "    plt.xlabel(\"Dataset Size (n)\")\n",
    "    plt.ylabel(\"Execution Time (seconds)\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_accident_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utilities",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
