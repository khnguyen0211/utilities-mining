{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Topic 0: Discovering Top-k periodic high-utility itemsets from uncertain databases**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Classes / Models**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "import datetime\n",
    "import heapq\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item:\n",
    "    def __init__(self, item: str, utility: int):\n",
    "        self.item = item\n",
    "        self.utility = utility\n",
    "        self._twu = 0\n",
    "\n",
    "    @property\n",
    "    def twu(self) -> int:\n",
    "        return self._twu\n",
    "\n",
    "    @twu.setter\n",
    "    def twu(self, value: int) -> None:\n",
    "        self._twu = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.item}\"\n",
    "        # return f\"({self.item}, {self.utility}, {self.twu})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Item):\n",
    "            return self.item == other.item and self.utility == other.utility\n",
    "        return False\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.item, self.utility))\n",
    "\n",
    "\n",
    "def check_order_condition(a: Item, b: Item) -> bool:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        a (Item): an item\n",
    "        b (Item): an item\n",
    "\n",
    "    Returns:\n",
    "        bool: return b < a\n",
    "    \"\"\"\n",
    "    if a.utility * b.utility < 0:\n",
    "        return a.utility < b.utility\n",
    "    elif a.utility * b.utility > 0:\n",
    "        if a.twu == b.twu:\n",
    "            if a.utility == b.utility:\n",
    "                return a.item > b.item\n",
    "            return b.utility > a.utility\n",
    "        return a.twu > b.twu\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_order_item_and_set(item: Item, item_set: set[Item]) -> bool:\n",
    "    \"\"\"_summary_\n",
    "    This function is used to check an item > item-set or not.\n",
    "    Example: a > {b, c}\n",
    "    Args:\n",
    "        item (Item): an item\n",
    "        item_set (set[Item]): an item set\n",
    "\n",
    "    Returns:\n",
    "        bool: return item > item_set\n",
    "    \"\"\"\n",
    "    for i in item_set:\n",
    "        if check_order_condition(item, i) == False:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "class TransItem:\n",
    "    def __init__(self, item: Item, quantity: int, probability: float):\n",
    "        self.item = item\n",
    "        self.quantity = quantity\n",
    "        self.probability = probability\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.item},{self.quantity},{self.probability}\"\n",
    "\n",
    "    def get_total_probability(self):\n",
    "        return self.quantity * self.probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "Periodic = namedtuple(\"Periodic\", [\"min_per\", \"max_per\", \"avg_per\"])\n",
    "\n",
    "@dataclass\n",
    "class Utilities:\n",
    "    tid: int\n",
    "    pro: float\n",
    "    pu: int\n",
    "    nu: int\n",
    "    ru: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transaction:\n",
    "    def __init__(self, id: int, trans_items: list[TransItem]):\n",
    "        self.id = id\n",
    "        self.trans_items_list = [trans_item.item for trans_item in trans_items]\n",
    "        self.trans_items_dict = {\n",
    "            trans_item.item: (trans_item.quantity, trans_item.probability)\n",
    "            for trans_item in trans_items\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Transaction(id={self.id}, items={list(self.trans_items_dict.keys())}, quantities={list(self.trans_items_dict.values())})\"\n",
    "\n",
    "    def contains_item_set(self, item_set: set[Item]) -> bool:\n",
    "        # Check directly against the dictionary keys\n",
    "        return item_set.issubset(self.trans_items_dict.keys())\n",
    "\n",
    "    def get_quantity_of_item(self, item: Item) -> int:\n",
    "        # Access quantity directly from the dictionary\n",
    "        return self.trans_items_dict.get(item, (0, 0))[0]\n",
    "\n",
    "    def get_probability_of_item(self, item: Item) -> float:\n",
    "        # Access probability directly from the dictionary\n",
    "        return self.trans_items_dict.get(item, (0, 0))[1]\n",
    "\n",
    "    def get_positive_utility_of_trans(self):\n",
    "        put = 0\n",
    "        positive_item = {item for item in self.get_items() if item.utility > 0}\n",
    "        for item in positive_item:\n",
    "            put += item.utility * self.get_quantity_of_item(item)\n",
    "        return put\n",
    "\n",
    "    def get_items(self) -> set[Item]:\n",
    "        return set(self.trans_items_dict.keys())\n",
    "\n",
    "    def get_probability_of_item_set(self, item_set: set[Item]) -> float:\n",
    "        if not self.contains_item_set(item_set):\n",
    "            return 0.0\n",
    "        total_probability = 1.0\n",
    "        for item in item_set:\n",
    "            total_probability *= self.get_probability_of_item(item)\n",
    "        return total_probability\n",
    "\n",
    "    def _calculate_utility(self, item_set: set[Item], condition: callable) -> int:\n",
    "        total_utility = 0\n",
    "        for item in item_set:\n",
    "            quantity = self.get_quantity_of_item(item)\n",
    "            if condition(item.utility):\n",
    "                total_utility += item.utility * quantity\n",
    "        return total_utility\n",
    "\n",
    "    def get_positive_utility_of_item_set(self, item_set: set[Item]) -> int:\n",
    "        return self._calculate_utility(item_set, lambda utility: utility > 0)\n",
    "\n",
    "    def get_negative_utility_of_item_set(self, item_set: set[Item]) -> int:\n",
    "        return self._calculate_utility(item_set, lambda utility: utility < 0)\n",
    "\n",
    "    def get_utility_of_item_set(self, item_set: set[Item]) -> int:\n",
    "        return self._calculate_utility(item_set, lambda utility: True)\n",
    "\n",
    "    def sort_trans_items_by_twu_and_utility(self) -> None:\n",
    "        def sort_key(item: Item) -> tuple:\n",
    "            return (0 if item.utility > 0 else 1, item.twu, -item.utility, item.item)\n",
    "\n",
    "        self.trans_items_list.sort(key=sort_key)\n",
    "\n",
    "    def get_remaining_utility_of_item_set(self, item_set: list[Item]) -> int:\n",
    "        ru = 0\n",
    "        if item_set:\n",
    "            last_item = item_set[-1]\n",
    "            index = self.trans_items_list.index(last_item)\n",
    "            for i in range(index + 1, len(self.trans_items_list)):\n",
    "                item = self.trans_items_list[i]\n",
    "                if item.utility > 0 and item not in item_set:\n",
    "                    quantity = self.trans_items_dict[item][0]\n",
    "                    ru += item.utility * quantity\n",
    "        return ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractList:\n",
    "    def __init__(self, item_set: set[\"Item\"], utility_values: list[\"Utilities\"]):\n",
    "        self.item_set = item_set\n",
    "        self.utility_values = utility_values\n",
    "\n",
    "    def get_ru(self) -> int:\n",
    "        return sum(i.ru for i in self.utility_values)\n",
    "\n",
    "    def get_pu(self) -> int:\n",
    "        return sum(i.pu for i in self.utility_values)\n",
    "\n",
    "    def get_nu(self) -> int:\n",
    "        return sum(i.nu for i in self.utility_values)\n",
    "\n",
    "    def get_pro(self) -> float:\n",
    "        return sum(i.pro for i in self.utility_values)\n",
    "\n",
    "    def get_utility(self) -> int:\n",
    "        return sum(i.pu + i.nu for i in self.utility_values)\n",
    "\n",
    "    def __repr__(self):\n",
    "        items_str = \", \".join(str(item) for item in self.item_set)\n",
    "        utility_values_str = \", \\n\".join(\n",
    "            str(utility) for utility in self.utility_values\n",
    "        )\n",
    "        return f\"{self.__class__.__name__}(\\n  Items: [{items_str}]\\n  Utility Values: \\n[{utility_values_str}]\\n)\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, AbstractList):\n",
    "            return False\n",
    "        return (\n",
    "            self.item_set == other.item_set\n",
    "            and self.utility_values == other.utility_values\n",
    "        )\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(frozenset(self.item_set)) ^ hash(tuple(self.utility_values))\n",
    "\n",
    "\n",
    "class PNUList(AbstractList):\n",
    "    def __init__(self, item_set: set[\"Item\"], utility_values: list[\"Utilities\"]):\n",
    "        super().__init__(item_set, utility_values)\n",
    "\n",
    "\n",
    "class MList(AbstractList):\n",
    "    def __init__(\n",
    "        self,\n",
    "        item_set: set[\"Item\"],\n",
    "        subset: PNUList,\n",
    "        subset_prefix: PNUList,\n",
    "        utility_values: list[\"Utilities\"],\n",
    "        pu: int,\n",
    "        ru: int,\n",
    "    ):\n",
    "        super().__init__(item_set, utility_values)\n",
    "        self.subset = subset\n",
    "        self.subset_prefix = subset_prefix\n",
    "        self.pu = pu\n",
    "        self.ru = ru\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"MList(\"\n",
    "            f\"item_set={list(self.item_set)}, \"\n",
    "            f\"subset={self.subset}, \"\n",
    "            f\"subset_prefix={self.subset_prefix})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityQueue:\n",
    "    def __init__(self, max_size: int):\n",
    "        self.max_size = max_size\n",
    "        self.heap: list[tuple[int, set[Item], Periodic]] = []\n",
    "        self.item_sets: set[frozenset] = set()\n",
    "\n",
    "    def push(self, utility: int, item_set: set):\n",
    "        fs_item_set = frozenset(item_set)\n",
    "        if fs_item_set in self.item_sets:\n",
    "            return\n",
    "\n",
    "        if len(self.heap) < self.max_size:\n",
    "            heapq.heappush(self.heap, (utility, item_set))\n",
    "            self.item_sets.add(fs_item_set)\n",
    "        else:\n",
    "            if utility > self.heap[0][0]:\n",
    "                removed = heapq.heappushpop(self.heap, (utility, item_set))\n",
    "                self.item_sets.remove(frozenset(removed[1]))\n",
    "                self.item_sets.add(fs_item_set)\n",
    "\n",
    "    def get_min_utility(self) -> int:\n",
    "        if self.heap:\n",
    "            return self.heap[0][0]\n",
    "        return float(\"-inf\")\n",
    "\n",
    "    def sort(self):\n",
    "        return sorted(self.heap, reverse=True)\n",
    "\n",
    "    def print_items(self):\n",
    "        for utility, item_set in self.sort():\n",
    "            print(f\"{item_set}: {utility}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Preliminaries and Formulation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.0. Transaction Dictionary**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transaction_dictionary(item_list: list[Item], database: list[Transaction]):\n",
    "    trans_dict: dict[Item, set[Transaction]] = {item: set() for item in item_list}\n",
    "    for trans in database:\n",
    "        trans_items = trans.get_items()\n",
    "        for item in trans_items:\n",
    "            trans_dict.get(item).add(trans)\n",
    "    return trans_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.1. Periodic Pattern**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_transId_dict(\n",
    "    item_list: list[Item], db: list[Transaction]\n",
    ") -> dict[Item, list[int]]:\n",
    "    transaction_index = {item: list() for item in item_list}\n",
    "    for trans in db:\n",
    "        for item in trans.trans_items_dict.keys():\n",
    "            transaction_index[item].append(trans.id)\n",
    "    return transaction_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_trans_ids_contained_item_set(\n",
    "    item_set: set[Item], create_item_transId_dict: dict[Item, list[int]]\n",
    ") -> list[int]:\n",
    "    trans_ids = list()\n",
    "    for item in item_set:\n",
    "        if not trans_ids:\n",
    "            trans_ids = set(create_item_transId_dict[item])\n",
    "            continue\n",
    "        trans_ids &= set(create_item_transId_dict[item])\n",
    "    return sorted(trans_ids) if trans_ids else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_max_avg_periodic_of_item_set(\n",
    "    item_set: set[Item], db: list[Transaction], transaction_index: dict[Item, list[int]]\n",
    "):\n",
    "    trans_ids = find_all_trans_ids_contained_item_set(item_set, transaction_index)\n",
    "    if not trans_ids:\n",
    "        return 0, 0, 0\n",
    "\n",
    "    m = len(trans_ids)\n",
    "    max_per, min_per, total_per = 0, float(\"inf\"), 0\n",
    "    prev = 0\n",
    "    for _, trans_id in enumerate(trans_ids):\n",
    "        per = trans_id - prev\n",
    "        max_per = max(max_per, per)\n",
    "        min_per = min(min_per, per)\n",
    "        total_per += per\n",
    "        prev = trans_id\n",
    "    final_per = len(db) - prev\n",
    "    max_per = max(max_per, final_per)\n",
    "    min_per = min(min_per, final_per)\n",
    "    total_per += final_per\n",
    "    avg_per = total_per / (m + 1)\n",
    "    return Periodic(min_per, max_per, avg_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.1 Transaction Weight Utility**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transaction_weight_utility(\n",
    "    item_set: set[Item], database: list[Transaction]\n",
    "):\n",
    "    twu = 0\n",
    "    for trans in database:\n",
    "        if trans.contains_item_set(item_set):\n",
    "            twu += trans.get_positive_utility_of_trans()\n",
    "    return twu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.3. Utility of an Itemset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_utility_of_item_set_in_database(\n",
    "    item_set: set[Item], trans_dict: dict[Item, set[Transaction]]\n",
    ") -> int:\n",
    "    transaction_set: set[Transaction] = set()\n",
    "    for item in item_set:\n",
    "        if not transaction_set:\n",
    "            transaction_set = set(trans_dict[item])\n",
    "            continue\n",
    "        transaction_set &= set(trans_dict[item])\n",
    "    utility = 0\n",
    "    for trans in transaction_set:\n",
    "        utility += trans.get_utility_of_item_set(item_set)\n",
    "    return utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Order of items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_order_condition(a: Item, b: Item) -> bool:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        a (Item): an item\n",
    "        b (Item): an item\n",
    "\n",
    "    Returns:\n",
    "        bool: return b < a\n",
    "    \"\"\"\n",
    "    if a.utility * b.utility < 0:\n",
    "        return a.utility < b.utility\n",
    "    elif a.utility * b.utility > 0:\n",
    "        if a.twu == b.twu:\n",
    "            if a.utility == b.utility:\n",
    "                return a.item > b.item\n",
    "            return b.utility > a.utility\n",
    "        return a.twu > b.twu\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_order_item_and_set(item: Item, item_set: set[Item]) -> bool:\n",
    "    \"\"\"_summary_\n",
    "    This function is used to check an item > item-set or not.\n",
    "    Example: a > {b, c}\n",
    "    Args:\n",
    "        item (Item): an item\n",
    "        item_set (set[Item]): an item set\n",
    "\n",
    "    Returns:\n",
    "        bool: return item > item_set\n",
    "    \"\"\"\n",
    "    for i in item_set:\n",
    "        if check_order_condition(item, i) == False:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_items_by_twu_and_utility(items: list[Item]) -> list[Item]:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        items (list[Item]): a list item\n",
    "\n",
    "    Returns:\n",
    "        list[Item]: a sorted list by two principle:\n",
    "        1. positive always takes priority over negative\n",
    "        2. ascending twu value\n",
    "    \"\"\"\n",
    "\n",
    "    def sort_key(item: Item) -> tuple:\n",
    "        return (0 if item.utility > 0 else 1, item.twu, -item.utility, item.item)\n",
    "\n",
    "    return sorted(items, key=sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.4. Potential / Expected Pattern**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability_of_item_set_in_database(\n",
    "    item_set: set[Item], trans_dict: dict[Item, set[Transaction]]\n",
    ") -> int:\n",
    "    transaction_set: set[Transaction] = set()\n",
    "    for item in item_set:\n",
    "        if not transaction_set:\n",
    "            transaction_set = set(trans_dict[item])\n",
    "            continue\n",
    "        transaction_set &= set(trans_dict[item])\n",
    "    if not transaction_set:\n",
    "        return 0.0\n",
    "    probability = 1.0\n",
    "    for trans in transaction_set:\n",
    "        probability *= trans.get_probability_of_item_set(item_set)\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability_and_utility_of_item_set_in_database(\n",
    "    item_set: set[Item], trans_dict: dict[Item, set[Transaction]]\n",
    "):\n",
    "    intersection_trans = set()\n",
    "    for item in item_set:\n",
    "        if not intersection_trans:\n",
    "            intersection_trans = set(trans_dict.get(item, set()))\n",
    "            continue\n",
    "        intersection_trans &= trans_dict.get(item)\n",
    "    p: float = 0.0\n",
    "    u: int = 0\n",
    "    ru: int = 0\n",
    "    sorted_itemset = sort_items_by_twu_and_utility(item_set)\n",
    "    for trans in intersection_trans:\n",
    "        p += trans.get_probability_of_item_set(item_set)\n",
    "        u += trans.get_utility_of_item_set(item_set)\n",
    "        ru += trans.get_remaining_utility_of_item_set(sorted_itemset)\n",
    "    return p, u, ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.4. Probability - TWU - Utility Bin Array**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prob_twu_utility_bin_array(\n",
    "    item_list: set[Item], database: list[Transaction]\n",
    ") -> tuple[list[int], list[int], list[int], dict[Item, int]]:\n",
    "    n = len(item_list)\n",
    "    twu_array = [0 for _ in range(n)]\n",
    "    prob_array = [0 for _ in range(n)]\n",
    "    utility_array = [0 for _ in range(n)]\n",
    "    item_dict = {item: idx for idx, item in enumerate(item_list)}\n",
    "    for trans in database:\n",
    "        ptu = trans.get_positive_utility_of_trans()\n",
    "        for item in trans.get_items():\n",
    "            index = item_dict.get(item, -1)\n",
    "            if index != -1:\n",
    "                twu_array[index] += ptu\n",
    "                prob_array[index] += trans.get_probability_of_item(item)\n",
    "                utility_array[index] += trans.get_quantity_of_item(item) * item.utility\n",
    "    return prob_array, twu_array, utility_array, item_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Remaining Utility**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_remaining_utility_of_item_set_in_database(\n",
    "    item_set: set[Item], trans_dict: dict[Item, set[Transaction]]\n",
    ") -> int:\n",
    "    transaction_set: set[Transaction] = set()\n",
    "    for item in item_set:\n",
    "        if not transaction_set:\n",
    "            transaction_set = set(trans_dict[item])\n",
    "            continue\n",
    "        transaction_set &= set(trans_dict[item])\n",
    "    utility = 0\n",
    "    for trans in transaction_set:\n",
    "        utility += trans.get_remaining_utility_of_item_set(item_set)\n",
    "    return utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Local Utility**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_local_utility(\n",
    "    alpha: set[Item], item: Item, database: list[Transaction]\n",
    ") -> int:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        alpha (set[Item]): an item set\n",
    "        item (Item): a combined item\n",
    "        database (list[Transaction]): database\n",
    "\n",
    "    Returns:\n",
    "        int: return a local utility value of item set\n",
    "    \"\"\"\n",
    "    lu = 0\n",
    "    sorted_alpha = sort_items_by_twu_and_utility(alpha)\n",
    "    for trans in database:\n",
    "        if trans.contains_item_set(alpha | {item}):\n",
    "            lu += trans.get_utility_of_item_set(\n",
    "                alpha\n",
    "            ) + trans.get_remaining_utility_of_item_set(sorted_alpha)\n",
    "    return lu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Subtree Utility**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_subtree_utility(\n",
    "    alpha: set[Item],\n",
    "    item: Item,\n",
    "    beta_db: set[Transaction],\n",
    "    trans_dict: dict[Item, set[Transaction]],\n",
    ") -> int:\n",
    "    item_trans: set[Transaction] = set(trans_dict.get(item))\n",
    "    general_trans: set[Transaction] = item_trans & beta_db\n",
    "    su = 0\n",
    "    sorted_alpha = sort_items_by_twu_and_utility(alpha)\n",
    "    if not alpha or check_order_condition(item, sorted_alpha[-1]):\n",
    "        for trans in general_trans:\n",
    "            su += (\n",
    "                trans.get_utility_of_item_set(alpha)\n",
    "                + trans.get_utility_of_item_set({item})\n",
    "                + trans.get_remaining_utility_of_item_set([item])\n",
    "            )\n",
    "    return su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Local & Subtree Utility Bin Array**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_local_subtree_bin_array(\n",
    "    alpha: set[Item], item_list: set[Item], database: list[Transaction]\n",
    ") -> tuple[list[int], list[int], list[float]]:\n",
    "    n = len(item_list)\n",
    "    lu_array = [0 for _ in range(n)]\n",
    "    su_array = [0 for _ in range(n)]\n",
    "    item_dict = {item: idx for idx, item in enumerate(item_list)}\n",
    "    sorted_alpha = sort_items_by_twu_and_utility(alpha)\n",
    "    set_item = set(item_list)\n",
    "    for trans in database:\n",
    "        alpha_util = trans.get_utility_of_item_set(alpha)\n",
    "        alpha_ru = trans.get_remaining_utility_of_item_set(sorted_alpha)\n",
    "        for item in trans.get_items():\n",
    "            index = item_dict.get(item, -1)\n",
    "            if index != -1:\n",
    "                lu_array[index] += alpha_util + alpha_ru\n",
    "                if item in set_item:\n",
    "                    item_utility = trans.get_quantity_of_item(item) * item.utility\n",
    "                    item_ru = trans.get_remaining_utility_of_item_set([item])\n",
    "                    if not alpha:\n",
    "                        su_array[index] += alpha_util + item_utility + item_ru\n",
    "                    else:\n",
    "                        if check_order_condition(item, sorted_alpha[-1]):\n",
    "                            su_array[index] += alpha_util + item_utility + item_ru\n",
    "    return lu_array, su_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_local_utility_bin_array(\n",
    "    alpha: set[Item], item_list: set[Item], database: list[Transaction]\n",
    "):\n",
    "    n = len(item_list)\n",
    "    lu_array = [0 for _ in range(n)]\n",
    "    item_dict = {item: idx for idx, item in enumerate(item_list)}\n",
    "    sorted_alpha = sort_items_by_twu_and_utility(alpha)\n",
    "    for trans in database:\n",
    "        alpha_util = trans.get_utility_of_item_set(alpha)\n",
    "        alpha_ru = trans.get_remaining_utility_of_item_set(sorted_alpha)\n",
    "        for item in trans.get_items():\n",
    "            index = item_dict.get(item, -1)\n",
    "            if index != -1:\n",
    "                lu_array[index] += alpha_util + alpha_ru\n",
    "    return lu_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_from_bin(\n",
    "    item: Item, bin: list[int | float], item_dict: dict[Item, int | float]\n",
    "):\n",
    "    index = item_dict.get(item, -1)\n",
    "    return bin[index] if index != -1 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 PNU List & MList**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pnu_lists(trans_dict: dict[Item, set[Transaction]]):\n",
    "    pnu_list = []\n",
    "    for item, transactions in trans_dict.items():\n",
    "        utility_values_list = []\n",
    "        pnu = PNUList({item}, utility_values_list)\n",
    "        for trans in transactions:\n",
    "            pro = trans.get_probability_of_item_set({item})\n",
    "            pu = trans.get_positive_utility_of_item_set({item})\n",
    "            nu = trans.get_negative_utility_of_item_set({item})\n",
    "            ru = trans.get_remaining_utility_of_item_set([item])\n",
    "            utility_values = Utilities(trans.id, pro, pu, nu, ru)\n",
    "            utility_values_list.append(utility_values)\n",
    "        pnu_list.append(pnu)\n",
    "    return pnu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tuple_by_trans_id(P: PNUList, target_trans_id: int) -> Utilities:\n",
    "    utilities_list: list[Utilities] = P.utility_values\n",
    "    for iTuple in utilities_list:\n",
    "        if iTuple.tid == target_trans_id:\n",
    "            return iTuple\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_list_construct(\n",
    "    P: PNUList,\n",
    "    Px: PNUList,\n",
    "    Py: PNUList,\n",
    "    min_util: int,\n",
    "    user_prob_threshold: float,\n",
    "):\n",
    "    if not Px or not Py or not Px.utility_values or not Py.utility_values:\n",
    "        return None\n",
    "\n",
    "    x = Px.item_set\n",
    "    y = Py.item_set\n",
    "    xy = x | y\n",
    "    utilities_list: list[Utilities] = []\n",
    "    Pxy = PNUList(xy, utilities_list)\n",
    "\n",
    "    y_dict = {utl.tid: utl for utl in Py.utility_values}\n",
    "    p_dict = (\n",
    "        {utl.tid: utl for utl in P.utility_values} if P and P.utility_values else {}\n",
    "    )\n",
    "\n",
    "    probability = Px.get_pro()\n",
    "    utility = Px.get_pu() + Px.get_ru()\n",
    "\n",
    "    for xTuple in Px.utility_values:\n",
    "        yTuple = y_dict.get(xTuple.tid, None)\n",
    "\n",
    "        if yTuple:\n",
    "            if P and P.utility_values:\n",
    "                pTuple = p_dict.get(xTuple.tid, None)\n",
    "                if pTuple:\n",
    "                    pro = 1e-10 if pTuple.pro == 0 else pTuple.pro\n",
    "                    xyTuple = Utilities(\n",
    "                        xTuple.tid,\n",
    "                        xTuple.pro * yTuple.pro / pro,\n",
    "                        xTuple.pu + yTuple.pu - pTuple.pu,\n",
    "                        xTuple.nu + yTuple.nu - pTuple.nu,\n",
    "                        yTuple.ru,\n",
    "                    )\n",
    "                    utilities_list.append(xyTuple)\n",
    "            else:\n",
    "                xyTuple = Utilities(\n",
    "                    xTuple.tid,\n",
    "                    xTuple.pro * yTuple.pro,\n",
    "                    xTuple.pu + yTuple.pu,\n",
    "                    xTuple.nu + yTuple.nu,\n",
    "                    yTuple.ru,\n",
    "                )\n",
    "                utilities_list.append(xyTuple)\n",
    "        else:\n",
    "            probability -= xTuple.pro\n",
    "            utility -= xTuple.pu + xTuple.ru\n",
    "\n",
    "            if probability < user_prob_threshold or utility < min_util:\n",
    "                return None\n",
    "    return Pxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlist_construct_1(X: AbstractList, Y: MList, du: int):\n",
    "    xy_item_set: set[Item] = X.item_set | Y.item_set\n",
    "    mlist = MList(xy_item_set, Y.subset, Y.subset_prefix, Y.utility_values, 0, du)\n",
    "    return mlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlist_construct_2(X: AbstractList, Y: PNUList, P: AbstractList, du: int):\n",
    "    xy_item_set: set[Item] = X.item_set | Y.item_set\n",
    "    mlist = MList(xy_item_set, Y, P, Y.utility_values, 0, du)\n",
    "    return mlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.5 Database Projection**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database_projection(\n",
    "    item_set: set[Item], trans_dict: dict[Item, set[Transaction]]\n",
    ") -> set[Transaction]:\n",
    "    intersection_trans = set()\n",
    "    for item in item_set:\n",
    "        if not intersection_trans:\n",
    "            intersection_trans = set(trans_dict.get(item, set()))\n",
    "            continue\n",
    "        intersection_trans &= trans_dict.get(item)\n",
    "    return intersection_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Pruning strategies**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 Max & Average Periodic**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 Transaction Weight Utility**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 The Estimated Utility Co-occurrence pruning Strategy with Threshold (EUCST)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eucst_dict(\n",
    "    sorted_item_list: list[Item],\n",
    "    database: list[Transaction],\n",
    "    trans_dict: dict[Item, set[Transaction]],\n",
    "    min_util: int,\n",
    "):\n",
    "    # Calculate all positive utility of transaction in database, and store in a dictionary\n",
    "    transaction_twu = {\n",
    "        trans: trans.get_positive_utility_of_trans() for trans in database\n",
    "    }\n",
    "    # Create a dictionary with key is a item and value is a list of transaction that contains item\n",
    "    eucst_dict = {}\n",
    "    n = len(sorted_item_list)\n",
    "    for i in range(n):\n",
    "        item1 = sorted_item_list[i]\n",
    "        for j in range(i + 1, n):\n",
    "            item2 = sorted_item_list[j]\n",
    "            # Using AND operator to get list of transaction that contains item set {item1, item2}\n",
    "            relevant_transactions: set[Transaction] = trans_dict.get(\n",
    "                item1, set()\n",
    "            ) & trans_dict.get(item2, set())\n",
    "            # Calculate sum utility in that transaction list, NOT in database\n",
    "            twu = sum(transaction_twu[trans] for trans in relevant_transactions)\n",
    "            if twu >= min_util:\n",
    "                eucst_dict[frozenset({item1, item2})] = twu\n",
    "    return eucst_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_eucst_dict(\n",
    "    eucst_dict: dict[frozenset, int], min_util: int\n",
    ") -> dict[frozenset, int]:\n",
    "    return {key: twu for key, twu in eucst_dict.items() if twu >= min_util}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 The concept of Leaf Itemset Utility (LIU)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_liu_dict(item_list: list, trans_dict: dict[Item, set[Transaction]]) -> dict:\n",
    "    n = len(item_list)\n",
    "    liu_dict: dict[frozenset[Item], int] = {}\n",
    "    # Generate all pairs of items using nested loops\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            item1 = item_list[i]\n",
    "            item2 = item_list[j]\n",
    "\n",
    "            # Retrieve transactions containing item1 and item2\n",
    "            trans1 = trans_dict.get(item1, set())\n",
    "            trans2 = trans_dict.get(item2, set())\n",
    "\n",
    "            # Find common transactions for the pair\n",
    "            relevant_transactions = trans1 & trans2\n",
    "\n",
    "            # Calculate the utility of the item pair\n",
    "            utility = sum(\n",
    "                trans.get_utility_of_item_set({item1, item2})\n",
    "                for trans in relevant_transactions\n",
    "            )\n",
    "\n",
    "            # Add the pair and its utility to the dictionary\n",
    "            liu_dict[frozenset((item1, item2))] = utility\n",
    "\n",
    "    return liu_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 Remaining Utility Pruning (RM)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3.1 Dynamical Upper Bound**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dynamic_upper_bound(\n",
    "    Y: AbstractList,\n",
    "    X: PNUList,\n",
    "    utility_array: list[int],\n",
    "    item_index_dict: dict[Item, int],\n",
    ") -> int:\n",
    "    x = next(iter(X.item_set - Y.item_set))\n",
    "    x_util = 0\n",
    "    if x.utility > 0:\n",
    "        x_util = get_value_from_bin(x, utility_array, item_index_dict)\n",
    "    if isinstance(Y, PNUList):\n",
    "        return Y.get_ru() + Y.get_pu() + x_util\n",
    "    elif isinstance(Y, MList):\n",
    "        return Y.ru + Y.pu + x_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Threshold raising strategies**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4.1 Positive Real Item Utility strategy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def priu_pruning(utility_arr: list[int], k: int) -> int:\n",
    "    sorted_util: list[int] = sorted(utility_arr, reverse=True)\n",
    "    if not sorted_util:\n",
    "        return 0\n",
    "    return sorted_util[-1] if k > len(utility_arr) else sorted_util[k - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4.1 Positive LIU-Exact strategy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pliue_strategy(lius: dict[frozenset[Item], int], k: int, current_min_util: int):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        lius (dict[frozenset[Item], int]): _description_\n",
    "        k (int): _description_co\n",
    "        current_min_util (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    piqu_liu = list()\n",
    "    for _, utility in lius.items():\n",
    "        piqu_liu.append(utility)\n",
    "\n",
    "    piqu_liu.sort(reverse=True)\n",
    "\n",
    "    max_index = len(piqu_liu) - 1 if k > len(piqu_liu) else k - 1\n",
    "    if piqu_liu[max_index] > current_min_util:\n",
    "        current_min_util = piqu_liu[max_index]\n",
    "    return current_min_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4.1 COVL strategy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covl_construct(\n",
    "    sorted_list: list[Item],\n",
    "    eucst_dict: dict[frozenset[Item], int],\n",
    "    utility_arr: list[int],\n",
    "    item_index_dict: dict[Item, int],\n",
    "    trans_dict: dict[Item, set[Transaction]],\n",
    "):\n",
    "    covl_list = list()\n",
    "    for i in range(len(sorted_list)):\n",
    "        x: Item = sorted_list[i]\n",
    "        coverage_list = list()\n",
    "        for j in range(i + 1, len(sorted_list)):\n",
    "            y: Item = sorted_list[j]\n",
    "            xy: set[Item] = {x, y}\n",
    "            key = frozenset(xy)\n",
    "            xy_twu = eucst_dict.get(key)\n",
    "            if x.twu == xy_twu:\n",
    "                coverage_list.append(y)\n",
    "        r = len(coverage_list)\n",
    "        if r == 0:\n",
    "            coverage_list.append(-1)\n",
    "        else:\n",
    "            util: int = 0\n",
    "            for z in range(0, r):\n",
    "                util += calculate_utility_of_item_set_in_database(\n",
    "                    {x, coverage_list[z]}, trans_dict\n",
    "                )\n",
    "            util -= (r - 1) * get_value_from_bin(x, utility_arr, item_index_dict)\n",
    "            covl_list.append(util)\n",
    "    covl_list.sort(reverse=True)\n",
    "    return covl_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Algorithms**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.1 PHUIM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phui_searching_procedure(\n",
    "    PList: PNUList,\n",
    "    lists: list[PNUList],\n",
    "    current_min_util: int,\n",
    "    min_per_threshold: int,\n",
    "    max_per_threshold: int,\n",
    "    min_avg_threshold: int,\n",
    "    max_avg_threshold: int,\n",
    "    user_prob_threshold: float,\n",
    "    database: list[Transaction],\n",
    "    eucs_dict: dict[frozenset[Item], int],\n",
    "    item_transId_dict: dict[Item, list[int]],\n",
    "    k: int,\n",
    "    topk_queue: PriorityQueue,\n",
    "):\n",
    "    for i in range(len(lists)):\n",
    "        XList: PNUList = lists[i]\n",
    "        XList_utility = XList.get_utility()\n",
    "        XList_prob = XList.get_pro()\n",
    "        XList_ru = XList.get_ru()\n",
    "        min_per, max_per, avg_per = find_min_max_avg_periodic_of_item_set(\n",
    "            XList.item_set, database, item_transId_dict\n",
    "        )\n",
    "        if (\n",
    "            XList_utility >= current_min_util\n",
    "            and round(XList_prob, 3) >= user_prob_threshold\n",
    "        ):\n",
    "\n",
    "            if (\n",
    "                min_per >= min_per_threshold\n",
    "                and max_per <= max_per_threshold\n",
    "                and avg_per >= min_avg_threshold\n",
    "                and avg_per <= max_avg_threshold\n",
    "            ):\n",
    "                topk_queue.push(XList_utility, XList.item_set, )\n",
    "                if len(topk_queue.heap) == k:\n",
    "                    current_min_util = topk_queue.sort()[k - 1][0]\n",
    "\n",
    "        if (\n",
    "            max_per <= max_per_threshold\n",
    "            and avg_per <= max_avg_threshold\n",
    "            and XList_ru + XList_utility >= current_min_util\n",
    "            and round(XList_prob, 3) >= user_prob_threshold\n",
    "        ):\n",
    "            new_lists: list[PNUList] = list()\n",
    "            for j in range(i + 1, len(lists)):\n",
    "                YList: PNUList = lists[j]\n",
    "                x = XList.item_set.difference(PList.item_set)\n",
    "                y = YList.item_set.difference(PList.item_set)\n",
    "                key = frozenset(x | y)\n",
    "                twu_value = eucs_dict.get(key, -1)\n",
    "                if twu_value >= current_min_util:\n",
    "                    ZList = utility_list_construct(\n",
    "                        PList, XList, YList, current_min_util, user_prob_threshold\n",
    "                    )\n",
    "                    if ZList:\n",
    "                        new_lists.append(ZList)\n",
    "            if new_lists:\n",
    "                phui_searching_procedure(\n",
    "                    XList,\n",
    "                    new_lists,\n",
    "                    current_min_util,\n",
    "                    min_per_threshold,\n",
    "                    max_per_threshold,\n",
    "                    min_avg_threshold,\n",
    "                    max_avg_threshold,\n",
    "                    user_prob_threshold,\n",
    "                    database,\n",
    "                    eucs_dict,\n",
    "                    item_transId_dict,\n",
    "                    k,\n",
    "                    topk_queue,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.2 PHUIM+**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phui_searching_procedure_plus(\n",
    "    PList: AbstractList,\n",
    "    lists: list[AbstractList],\n",
    "    current_min_util: int,\n",
    "    min_per_threshold: int,\n",
    "    max_per_threshold: int,\n",
    "    min_avg_threshold: int,\n",
    "    max_avg_threshold: int,\n",
    "    user_prob_threshold: float,\n",
    "    db: list[Transaction],\n",
    "    utility_array: list[int],\n",
    "    item_index_dict: dict[Item, int],\n",
    "    eucs_dict: dict[frozenset[Item], int],\n",
    "    item_transId_dict: dict[Item, list[int]],\n",
    "    k: int,\n",
    "    topk_queue: PriorityQueue,\n",
    ") -> None:\n",
    "    for i in range(len(lists)):\n",
    "        XList: AbstractList = lists[i]\n",
    "        x_utility = XList.get_utility()\n",
    "        x_prob = XList.get_pro()\n",
    "        x_ru = XList.get_ru()\n",
    "        min_per, max_per, avg_per = find_min_max_avg_periodic_of_item_set(\n",
    "            XList.item_set, db, item_transId_dict\n",
    "        )\n",
    "        if x_utility >= current_min_util and round(x_prob, 3) >= user_prob_threshold:\n",
    "            if (\n",
    "                min_per >= min_per_threshold\n",
    "                and max_per <= max_per_threshold\n",
    "                and avg_per >= min_avg_threshold\n",
    "                and avg_per <= max_avg_threshold\n",
    "            ):\n",
    "                topk_queue.push(x_utility, XList.item_set)\n",
    "                if len(topk_queue.heap) == k:\n",
    "                    current_min_util = topk_queue.sort()[k - 1][0]\n",
    "        if (\n",
    "            max_per <= max_per_threshold\n",
    "            and avg_per <= max_avg_threshold\n",
    "            and x_ru + x_utility >= current_min_util\n",
    "            and round(x_prob, 3) >= user_prob_threshold\n",
    "        ):\n",
    "            new_lists: list[PNUList | MList] = list()\n",
    "            for j in range(i + 1, len(lists)):\n",
    "                YList: AbstractList = lists[j]\n",
    "                x: set[Item] = XList.item_set.difference(PList.item_set)\n",
    "                y: set[Item] = YList.item_set.difference(PList.item_set)\n",
    "                twu_value: int = eucs_dict.get(frozenset(x | y), -1)\n",
    "                if twu_value >= current_min_util:\n",
    "                    du = calculate_dynamic_upper_bound(\n",
    "                        YList, XList, utility_array, item_index_dict\n",
    "                    )\n",
    "                    if du >= current_min_util:\n",
    "                        if isinstance(YList, MList):\n",
    "                            ZList: PNUList = utility_list_construct(\n",
    "                                YList.subset_prefix,\n",
    "                                XList,\n",
    "                                YList.subset,\n",
    "                                current_min_util,\n",
    "                                user_prob_threshold,\n",
    "                            )\n",
    "                            if ZList:\n",
    "                                new_lists.append(ZList)\n",
    "                        else:\n",
    "                            ZList: PNUList = utility_list_construct(\n",
    "                                PList,\n",
    "                                XList,\n",
    "                                YList,\n",
    "                                current_min_util,\n",
    "                                user_prob_threshold,\n",
    "                            )\n",
    "                            if ZList:\n",
    "                                new_lists.append(ZList)\n",
    "                    else:\n",
    "                        if isinstance(YList, MList):\n",
    "                            ZMlist: MList = mlist_construct_1(XList, YList, du)\n",
    "                            new_lists.append(ZMlist)\n",
    "                        else:\n",
    "                            ZMlist: MList = mlist_construct_2(XList, YList, PList, du)\n",
    "                            new_lists.append(ZMlist)\n",
    "            if new_lists:\n",
    "                phui_searching_procedure_plus(\n",
    "                    XList,\n",
    "                    new_lists,\n",
    "                    current_min_util,\n",
    "                    min_per_threshold,\n",
    "                    max_per_threshold,\n",
    "                    min_avg_threshold,\n",
    "                    max_avg_threshold,\n",
    "                    user_prob_threshold,\n",
    "                    db,\n",
    "                    utility_array,\n",
    "                    item_index_dict,\n",
    "                    eucs_dict,\n",
    "                    item_transId_dict,\n",
    "                    k,\n",
    "                    topk_queue,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_mining_based_on_PHUI(\n",
    "    database: list[Transaction],\n",
    "    item_list: list[Item],\n",
    "    k: int,\n",
    "    min_per_threshold: int,\n",
    "    max_per_threshold: int,\n",
    "    min_avg_threshold: int,\n",
    "    max_avg_threshold: int,\n",
    "    min_prob: float,\n",
    "    is_plus: bool,\n",
    ") -> PriorityQueue:\n",
    "    t1 = datetime.datetime.now()\n",
    "    # Create priority to contains top-k HUI\n",
    "    topk_queue = PriorityQueue(k)\n",
    "    user_prob_threshold = min_prob * len(database)\n",
    "\n",
    "    # Create a utility array & and a dictionary to search\n",
    "    prob_arr, twu_arr, utility_arr, item_index_dict = create_prob_twu_utility_bin_array(\n",
    "        item_list, database\n",
    "    )\n",
    "    positive_utility_arr = [u for u in utility_arr if u > 0]\n",
    "    # First update min_util = the k-th highest utility value (using RIU strategy)\n",
    "    current_min_util: int = priu_pruning(positive_utility_arr, k)\n",
    "\n",
    "    # Create a list that contains all items is unqualified\n",
    "    removed_list: set[Item] = set()\n",
    "\n",
    "    # Create a diction contains item: list[transaction_id]\n",
    "    item_transId_dict: dict[Item, list[int]] = create_item_transId_dict(\n",
    "        item_list, database\n",
    "    )\n",
    "    for i in range(len(item_list)):\n",
    "        _, max_per, avg_per = find_min_max_avg_periodic_of_item_set(\n",
    "            {item_list[i]}, database, item_transId_dict\n",
    "        )\n",
    "        if (\n",
    "            max_per <= max_per_threshold\n",
    "            and avg_per <= max_avg_threshold\n",
    "            and twu_arr[i] >= current_min_util\n",
    "            and round(prob_arr[i], 3) >= user_prob_threshold\n",
    "        ):\n",
    "            item_list[i].twu = twu_arr[i]\n",
    "        else:\n",
    "            removed_list.add(item_list[i])\n",
    "    # Remove unqualified item\n",
    "    new_distinct_items = [item for item in item_list if item not in removed_list]\n",
    "    # Sort item list by order\n",
    "    new_distinct_items = sort_items_by_twu_and_utility(new_distinct_items)\n",
    "\n",
    "    # Remove unqualified items from transaction\n",
    "    for trans in database:\n",
    "        for item in removed_list:\n",
    "            trans.trans_items_dict.pop(item, None)\n",
    "            try:\n",
    "                trans.trans_items_list.remove(item)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        trans.sort_trans_items_by_twu_and_utility()\n",
    "\n",
    "    # Convert database - list[Transaction] into dict[Item, set[Transaction]]\n",
    "    trans_dict: dict[Item, set[Transaction]] = create_transaction_dictionary(\n",
    "        new_distinct_items, database\n",
    "    )\n",
    "    # Create list[AbstractList],\n",
    "    pnu_lists: list[PNUList] = create_pnu_lists(trans_dict)\n",
    "\n",
    "    # Create EUCST dict that contain twu > current_min_util of all 2-item-set\n",
    "    eucst_dict: dict[frozenset[Item], int] = create_eucst_dict(\n",
    "        new_distinct_items, database, trans_dict, current_min_util\n",
    "    )\n",
    "\n",
    "    # Create CUDM dict that contain utility of all 2-item-set\n",
    "    cudm_dict: dict[frozenset[Item], int] = create_liu_dict(\n",
    "        new_distinct_items, trans_dict\n",
    "    )\n",
    "\n",
    "    # Update and increase current_min_util\n",
    "    if cudm_dict:\n",
    "        cud: int = pliue_strategy(cudm_dict, k, current_min_util)\n",
    "        # Update current min_util = the k-th highest utility in CUDM dict\n",
    "        current_min_util = max(current_min_util, cud)\n",
    "\n",
    "    covl: list[int] = covl_construct(\n",
    "        new_distinct_items, eucst_dict, utility_arr, item_index_dict, trans_dict\n",
    "    )\n",
    "    # Update and increase current_min_util\n",
    "    if covl:\n",
    "        current_min_util = max(current_min_util, covl[min(len(covl), k) - 1])\n",
    "    eucst_dict: dict[frozenset, int] = update_eucst_dict(eucst_dict, current_min_util)\n",
    "    root = PNUList({}, list())\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(\"phase 1 util: \" + str(current_min_util))\n",
    "    print(\"phase 1 take time: \" + str(t2 - t1))\n",
    "    if is_plus:\n",
    "        phui_searching_procedure_plus(\n",
    "            root,\n",
    "            pnu_lists,\n",
    "            current_min_util,\n",
    "            min_per_threshold,\n",
    "            max_per_threshold,\n",
    "            min_avg_threshold,\n",
    "            max_avg_threshold,\n",
    "            user_prob_threshold,\n",
    "            database,\n",
    "            utility_arr,\n",
    "            item_index_dict,\n",
    "            eucst_dict,\n",
    "            item_transId_dict,\n",
    "            k,\n",
    "            topk_queue,\n",
    "        )\n",
    "    else:\n",
    "        phui_searching_procedure(\n",
    "            root,\n",
    "            pnu_lists,\n",
    "            current_min_util,\n",
    "            min_per_threshold,\n",
    "            max_per_threshold,\n",
    "            min_avg_threshold,\n",
    "            max_avg_threshold,\n",
    "            user_prob_threshold,\n",
    "            database,\n",
    "            eucst_dict,\n",
    "            item_transId_dict,\n",
    "            k,\n",
    "            topk_queue,\n",
    "        )\n",
    "    t3 = datetime.datetime.now()\n",
    "    print(\"phase 2 util: \" + str(current_min_util))\n",
    "    print(\"phase 2 take time: \" + str(t3 - t2))\n",
    "    print(t2 - t1)\n",
    "    return topk_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.3 EFIM**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efim_global_search(\n",
    "    alpha: set[Item],\n",
    "    primary: list[Item],\n",
    "    secondary: list[Item],\n",
    "    min_util: int,\n",
    "    min_per_threshold: int,\n",
    "    max_per_threshold: int,\n",
    "    min_avg_threshold: int,\n",
    "    max_avg_threshold: int,\n",
    "    user_prob_threshold: float,\n",
    "    k: int,\n",
    "    item_dict: dict[Item, int],\n",
    "    topk_queue: PriorityQueue,\n",
    "    trans_dict: dict[Item, set[Transaction]],\n",
    "    item_transId_dict: dict[Item, list[int]],\n",
    "    database: list[Transaction],\n",
    ") -> None:\n",
    "    for pri_item in primary:\n",
    "        beta: set[Item] = alpha | {pri_item}\n",
    "        prob, util, ru = calculate_probability_and_utility_of_item_set_in_database(\n",
    "            beta, trans_dict\n",
    "        )\n",
    "        min_per, max_per, avg_per = find_min_max_avg_periodic_of_item_set(\n",
    "            beta, database, item_transId_dict\n",
    "        )\n",
    "        if util >= min_util and round(prob, 3) >= user_prob_threshold:\n",
    "            if (\n",
    "                min_per >= min_per_threshold\n",
    "                and max_per <= max_per_threshold\n",
    "                and avg_per >= min_avg_threshold\n",
    "                and avg_per <= max_avg_threshold\n",
    "            ):\n",
    "                topk_queue.push(util, beta)\n",
    "                if len(topk_queue.heap) == k:\n",
    "                    min_util = topk_queue.sort()[k - 1][0]\n",
    "        if (\n",
    "            max_per <= max_per_threshold\n",
    "            and avg_per <= max_avg_threshold\n",
    "            and ru + util >= min_util\n",
    "            and round(prob, 3) >= user_prob_threshold\n",
    "        ):\n",
    "            i = secondary.index(pri_item)\n",
    "            if i != -1 and i + 1 < len(secondary):\n",
    "                second_item = secondary[i + 1]\n",
    "                if (\n",
    "                    util < min_util or round(prob, 3) < user_prob_threshold\n",
    "                ) and second_item.utility < 0:\n",
    "                    continue\n",
    "\n",
    "            beta_dp: set[Transaction] = create_database_projection(beta, trans_dict)\n",
    "            lu_arr = create_local_utility_bin_array(beta, secondary, beta_dp)\n",
    "            new_primary: list[Item] = list()\n",
    "            new_secondary: list[Item] = list()\n",
    "            for j in range(i + 1, len(secondary)):\n",
    "                if lu_arr[j] >= min_util:\n",
    "                    new_secondary.append(secondary[j])\n",
    "                    if (\n",
    "                        calculate_subtree_utility(\n",
    "                            beta, secondary[j], beta_dp, trans_dict\n",
    "                        )\n",
    "                        >= min_util\n",
    "                    ):\n",
    "                        new_primary.append(secondary[j])\n",
    "\n",
    "            if new_primary and new_secondary:\n",
    "                efim_global_search(\n",
    "                    beta,\n",
    "                    new_primary,\n",
    "                    new_secondary,\n",
    "                    min_util,\n",
    "                    min_per_threshold,\n",
    "                    max_per_threshold,\n",
    "                    min_avg_threshold,\n",
    "                    max_avg_threshold,\n",
    "                    user_prob_threshold,\n",
    "                    k,\n",
    "                    item_dict,\n",
    "                    topk_queue,\n",
    "                    trans_dict,\n",
    "                    item_transId_dict,\n",
    "                    database,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_mining_based_on_EFIM(\n",
    "    database: list[Transaction],\n",
    "    item_list: list[Item],\n",
    "    k: int,\n",
    "    min_per_threshold: int,\n",
    "    max_per_threshold: int,\n",
    "    min_avg_threshold: int,\n",
    "    max_avg_threshold: int,\n",
    "    min_prob: float,\n",
    ") -> PriorityQueue:\n",
    "    t1 = datetime.datetime.now()\n",
    "    if k <= 0:\n",
    "        return\n",
    "    # Init alpha with empty set\n",
    "    alpha: set[Item] = set()\n",
    "    topk_queue = PriorityQueue(k)\n",
    "    current_min_util = 0\n",
    "    user_prob_threshold = min_prob * len(database)\n",
    "\n",
    "    prob_arr, twu_arr, utility_arr, item_dict = create_prob_twu_utility_bin_array(\n",
    "        item_list, database\n",
    "    )\n",
    "    # Get only positive item set\n",
    "    positive_utility_list: list[Item] = [\n",
    "        utility for utility in utility_arr if utility > 0\n",
    "    ]\n",
    "\n",
    "    # Update current_min_util = the k-th largest in utility array\n",
    "    current_min_util: int = priu_pruning(positive_utility_list, k)\n",
    "\n",
    "    # Create secondary list\n",
    "    secondary = list()\n",
    "\n",
    "    item_transId_dict: dict[Item, list[int]] = create_item_transId_dict(\n",
    "        item_list, database\n",
    "    )\n",
    "\n",
    "    for i in range(len(item_list)):\n",
    "        if round(prob_arr[i], 3) >= user_prob_threshold and twu_arr[i] >= current_min_util:\n",
    "            _, max_per, avg_per = find_min_max_avg_periodic_of_item_set(\n",
    "                {item_list[i]}, database, item_transId_dict\n",
    "            )\n",
    "            if max_per <= max_per_threshold and avg_per <= max_avg_threshold:\n",
    "                item_list[i].twu = twu_arr[i]\n",
    "                secondary.append(item_list[i])\n",
    "\n",
    "    # Create removed_list contains item unqualified\n",
    "    removed_list = set(item_list).difference(secondary)\n",
    "\n",
    "    # Remove those items in removed_list from database\n",
    "    for trans in database:\n",
    "        for item in removed_list:\n",
    "            trans.trans_items_dict.pop(item, None)\n",
    "            try:\n",
    "                trans.trans_items_list.remove(item)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        trans.sort_trans_items_by_twu_and_utility()\n",
    "\n",
    "    # Convert database (list[Transaction]) to trans_dict (dict[Item, set[Transaction]])\n",
    "    trans_dict: dict[Item, set[Transaction]] = create_transaction_dictionary(\n",
    "        secondary, database\n",
    "    )\n",
    "    # Create liu dict, to update current_min_util\n",
    "    lius: dict[frozenset[Item], int] = create_liu_dict(secondary, trans_dict)\n",
    "    current_min_util = pliue_strategy(lius, k, current_min_util)\n",
    "\n",
    "    secondary = sort_items_by_twu_and_utility(secondary)\n",
    "\n",
    "    eucst_dict: dict[frozenset[Item], int] = create_eucst_dict(\n",
    "        secondary, database, trans_dict, current_min_util\n",
    "    )\n",
    "    covl: list[int] = covl_construct(\n",
    "        secondary, eucst_dict, utility_arr, item_dict, trans_dict\n",
    "    )\n",
    "    # Update and increase current_min_util\n",
    "    if covl:\n",
    "        current_min_util = max(current_min_util, covl[min(len(covl), k) - 1])\n",
    "\n",
    "    # Create local & subtree bin array for all item\n",
    "    _, su_array = create_local_subtree_bin_array(alpha, secondary, database)\n",
    "    # Create primary & secondary list\n",
    "    primary: list[Item] = [\n",
    "        secondary[i] for i in range(len(secondary)) if su_array[i] >= current_min_util\n",
    "    ]\n",
    "\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(\"phase 1 util: \" + str(current_min_util))\n",
    "    print(\"phase 1 take time: \" + str(t2 - t1))\n",
    "    t1 = datetime.datetime.now()\n",
    "\n",
    "    efim_global_search(\n",
    "        alpha,\n",
    "        primary,\n",
    "        secondary,\n",
    "        current_min_util,\n",
    "        min_per_threshold,\n",
    "        max_per_threshold,\n",
    "        min_avg_threshold,\n",
    "        max_avg_threshold,\n",
    "        user_prob_threshold,\n",
    "        k,\n",
    "        item_dict,\n",
    "        topk_queue,\n",
    "        trans_dict,\n",
    "        item_transId_dict,\n",
    "        database,\n",
    "    )\n",
    "    t3 = datetime.datetime.now()\n",
    "    print(\"phase 2 util: \" + str(current_min_util))\n",
    "    print(\"phase 2 take time: \" + str(t3 - t2))\n",
    "    return topk_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Testing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Item(\"a\", 6)\n",
    "# b = Item(\"b\", 7)\n",
    "# c = Item(\"c\", 1)\n",
    "# d = Item(\"d\", -5)\n",
    "# e = Item(\"e\", 3)\n",
    "\n",
    "# t1_trans_items = {TransItem(b, 3, 0.85), TransItem(c, 1, 1.0), TransItem(d, 2, 0.70)}\n",
    "\n",
    "# t2_trans_items = {\n",
    "#     TransItem(a, 1, 1.0),\n",
    "#     TransItem(b, 1, 0.60),\n",
    "#     TransItem(c, 3, 0.75),\n",
    "#     TransItem(e, 1, 0.40),\n",
    "# }\n",
    "\n",
    "# t3_trans_items = {\n",
    "#     TransItem(a, 1, 0.55),\n",
    "#     TransItem(b, 2, 0.60),\n",
    "#     TransItem(c, 4, 1.0),\n",
    "#     TransItem(d, 1, 0.90),\n",
    "#     TransItem(e, 5, 0.40),\n",
    "# }\n",
    "\n",
    "# t4_trans_items = {TransItem(b, 3, 0.90), TransItem(d, 1, 0.45)}\n",
    "\n",
    "# t5_trans_items = {\n",
    "#     TransItem(a, 4, 1.0),\n",
    "#     TransItem(c, 3, 0.85),\n",
    "#     TransItem(d, 2, 0.70),\n",
    "#     TransItem(e, 2, 0.45),\n",
    "# }\n",
    "\n",
    "# t1 = Transaction(1, t1_trans_items)\n",
    "# t2 = Transaction(2, t2_trans_items)\n",
    "# t3 = Transaction(3, t3_trans_items)\n",
    "# t4 = Transaction(4, t4_trans_items)\n",
    "# t5 = Transaction(5, t5_trans_items)\n",
    "\n",
    "# item_list = [a, b, c, d, e]\n",
    "# db1 = [t1, t2, t3, t4, t5]\n",
    "# db2 = [t1, t2, t3, t4, t5]\n",
    "# db3 = [t1, t2, t3, t4, t5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Item(\"a\", 3)\n",
    "b = Item(\"b\", 6)\n",
    "c = Item(\"c\", -3)\n",
    "d = Item(\"d\", 12)\n",
    "e = Item(\"e\", -5)\n",
    "f = Item(\"f\", -2)\n",
    "g = Item(\"g\", -1)\n",
    "\n",
    "t1_trans_items = [\n",
    "    TransItem(a, 5, 0.0),\n",
    "    TransItem(b, 2, 0.0),\n",
    "    TransItem(c, 1, 0.0),\n",
    "    TransItem(d, 2, 0.0),\n",
    "]\n",
    "\n",
    "t2_trans_items = [\n",
    "    TransItem(a, 1, 0.0),\n",
    "    TransItem(c, 1, 0.0),\n",
    "    TransItem(d, 1, 0.0),\n",
    "    TransItem(g, 3, 0.0),\n",
    "]\n",
    "\n",
    "t3_trans_items = [\n",
    "    TransItem(a, 1, 0.0),\n",
    "    TransItem(c, 1, 0.0),\n",
    "    TransItem(f, 1, 0.0),\n",
    "]\n",
    "\n",
    "t4_trans_items = [TransItem(a, 1, 0.0), TransItem(f, 4, 0.0), TransItem(g, 2, 0.0)]\n",
    "\n",
    "t5_trans_items = [\n",
    "    TransItem(a, 1, 0.0),\n",
    "    TransItem(g, 2, 0.0),\n",
    "]\n",
    "\n",
    "t6_trans_items = [\n",
    "    TransItem(b, 3, 0.0),\n",
    "    TransItem(c, 2, 0.0),\n",
    "    TransItem(d, 3, 0.0),\n",
    "    TransItem(e, 1, 0.0),\n",
    "]\n",
    "\n",
    "t7_trans_items = [\n",
    "    TransItem(c, 6, 0.0),\n",
    "    TransItem(e, 4, 0.0),\n",
    "]\n",
    "t8_trans_items = [\n",
    "    TransItem(e, 1, 0.0),\n",
    "    TransItem(f, 3, 0.0),\n",
    "]\n",
    "t1 = Transaction(1, t1_trans_items)\n",
    "t2 = Transaction(2, t2_trans_items)\n",
    "t3 = Transaction(3, t3_trans_items)\n",
    "t4 = Transaction(4, t4_trans_items)\n",
    "t5 = Transaction(5, t5_trans_items)\n",
    "t6 = Transaction(6, t6_trans_items)\n",
    "t7 = Transaction(7, t7_trans_items)\n",
    "t8 = Transaction(8, t8_trans_items)\n",
    "\n",
    "item_list_1 = list([a, b, c, d, e, f, g])\n",
    "item_list_2 = list([a, b, c, d, e, f, g])\n",
    "item_list_3 = list([a, b, c, d, e, f, g])\n",
    "db1 = list([t1, t2, t3, t4, t5, t6, t7, t8])\n",
    "db2 = list([t1, t2, t3, t4, t5, t6, t7, t8])\n",
    "db3 = list([t1, t2, t3, t4, t5, t6, t7, t8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "prob_threshold = 0.0\n",
    "min_per_threshold = 1\n",
    "max_per_threshold = 5\n",
    "min_avg_threshold = 1\n",
    "max_avg_threshold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase 1 util: 60\n",
      "phase 1 take time: 0:00:00.005506\n",
      "phase 2 util: 60\n",
      "phase 2 take time: 0:00:00\n",
      "0:00:00.005506\n",
      "{b, d}: 90\n",
      "{b, d, c}: 81\n",
      "{d}: 72\n",
      "{d, c}: 60\n",
      "topk_mining_based_on_PHUI(false): 4\n",
      "topk_mining_based_on_PHUI(false): 0:00:00.005506\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.datetime.now()\n",
    "rs1 = topk_mining_based_on_PHUI(\n",
    "    db1,\n",
    "    item_list_1,\n",
    "    k,\n",
    "    min_per_threshold,\n",
    "    max_per_threshold,\n",
    "    min_avg_threshold,\n",
    "    max_avg_threshold,\n",
    "    prob_threshold,\n",
    "    False,\n",
    ")\n",
    "rs1.print_items()\n",
    "t2 = datetime.datetime.now()\n",
    "print(\"topk_mining_based_on_PHUI(false): \" + str(len(rs1.heap)))\n",
    "print(\"topk_mining_based_on_PHUI(false): \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase 1 util: 60\n",
      "phase 1 take time: 0:00:00.000520\n",
      "phase 2 util: 60\n",
      "phase 2 take time: 0:00:00.000519\n",
      "0:00:00.000520\n",
      "{b, d}: 90\n",
      "{b, d, c}: 81\n",
      "{d}: 72\n",
      "{d, c}: 60\n",
      "topk_mining_based_on_PHUI(true): 4\n",
      "topk_mining_based_on_PHUI(true): 0:00:00.001039\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.datetime.now()\n",
    "rs2 = topk_mining_based_on_PHUI(\n",
    "    db2,\n",
    "    item_list_2,\n",
    "    k,\n",
    "    min_per_threshold,\n",
    "    max_per_threshold,\n",
    "    min_avg_threshold,\n",
    "    max_avg_threshold,\n",
    "    prob_threshold,\n",
    "    True,\n",
    ")\n",
    "rs2.print_items()\n",
    "t2 = datetime.datetime.now()\n",
    "print(\"topk_mining_based_on_PHUI(true): \" + str(len(rs2.heap)))\n",
    "print(\"topk_mining_based_on_PHUI(true): \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase 1 util: 60\n",
      "phase 1 take time: 0:00:00\n",
      "phase 2 util: 60\n",
      "phase 2 take time: 0:00:00.000733\n",
      "{b, d}: 90\n",
      "{b, d, c}: 81\n",
      "{d}: 72\n",
      "{d, c}: 60\n",
      "topk_mining_based_on_EFIM: 4\n",
      "topk_mining_based_on_EFIM: 0:00:00.000733\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.datetime.now()\n",
    "rs3 = topk_mining_based_on_EFIM(\n",
    "    db3,\n",
    "    item_list_3,\n",
    "    k,\n",
    "    min_per_threshold,\n",
    "    max_per_threshold,\n",
    "    min_avg_threshold,\n",
    "    max_avg_threshold,\n",
    "    prob_threshold,\n",
    ")\n",
    "rs3.print_items()\n",
    "t2 = datetime.datetime.now()\n",
    "print(\"topk_mining_based_on_EFIM: \" + str(len(rs3.heap)))\n",
    "print(\"topk_mining_based_on_EFIM: \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_list1 = [Item(f\"i{i+1}\", random.randint(-10, 10)) for i in range(30)]\n",
    "# item_list2 = list(item_list1)\n",
    "# item_list3 = list(item_list1)\n",
    "# db1 = list()\n",
    "# db2 = list()\n",
    "# db3 = list()\n",
    "# for transaction_id in range(1, 1001):\n",
    "#     trans_items = list()\n",
    "#     selected_items = random.sample(item_list1, random.randint(15, 25))\n",
    "#     for item in selected_items:\n",
    "#         quantity = random.randint(1, 10)\n",
    "#         probability = round(random.uniform(0.30, 0.99), 2)\n",
    "#         trans_item = TransItem(item, quantity, probability)\n",
    "#         trans_items.append(trans_item)\n",
    "#     transaction = Transaction(transaction_id, trans_items)\n",
    "#     db1.append(transaction)\n",
    "#     db2.append(transaction)\n",
    "#     db3.append(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 10\n",
    "# prob_threshold = 0.0001\n",
    "# min_per_threshold = 1\n",
    "# max_per_threshold = 1000\n",
    "# min_avg_threshold = 1\n",
    "# max_avg_threshold = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs1 = topk_mining_based_on_PHUI(\n",
    "#     db1,\n",
    "#     item_list1,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "#     False,\n",
    "# )\n",
    "# rs1.print_items()\n",
    "# t2 = datetime.datetime.now()\n",
    "# print(\"topk_mining_based_on_PHUI(false): \" + str(len(rs1.heap)))\n",
    "# print(\"topk_mining_based_on_PHUI(false): \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs2 = topk_mining_based_on_PHUI(\n",
    "#     db2,\n",
    "#     item_list2,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "#     True,\n",
    "# )\n",
    "# rs2.print_items()\n",
    "# t2 = datetime.datetime.now()\n",
    "# print(\"topk_mining_based_on_PHUI(true): \" + str(len(rs2.heap)))\n",
    "# print(\"topk_mining_based_on_PHUI(true): \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs3 = topk_mining_based_on_EFIM(\n",
    "#     db3,\n",
    "#     item_list3,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "# )\n",
    "# rs3.print_items()\n",
    "# t2 = datetime.datetime.now()\n",
    "# print(\"topk_mining_based_on_EFIM: \" + str(len(rs3.heap)))\n",
    "# print(\"topk_mining_based_on_EFIM: \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Experiments and Evaluation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_item_file(item_file_path: str):\n",
    "    item_set: set[Item] = set()\n",
    "    try:\n",
    "        with open(item_file_path) as file:\n",
    "            for line in file:\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                arr = line.split(\", \")\n",
    "                item: Item = Item(arr[0], int(arr[1]))\n",
    "                item_set.add(item)\n",
    "        return item_set\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"The file at {item_file_path} does not exist.\")\n",
    "    except IOError as e:\n",
    "        raise IOError(f\"An error occurred while reading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_item_by_name(name: str, item_set: set[Item]) -> Item:\n",
    "    for item in item_set:\n",
    "        if(item.item == name):\n",
    "            return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_aggregate_data(\n",
    "    file_path: str, lines: int\n",
    ") -> tuple[list[Item], list[Transaction]]:\n",
    "    item_set: set[Item] = set()\n",
    "    item_set_name: set[str] = set()\n",
    "    trans_item: list[TransItem] = list()\n",
    "    database: list[Transaction] = list()\n",
    "    try:\n",
    "        with open(file_path) as file:\n",
    "            tid: int = 1\n",
    "            for line in file:\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                arr = line.split(\":\")\n",
    "                left_arr = arr[0].split(\" \")\n",
    "                right_arr = arr[2].split(\" \")\n",
    "                for i in left_arr:\n",
    "                    if i not in item_set_name:\n",
    "                        item_set_name.add(i)\n",
    "                        item: Item = Item(i, random.randint(-10, 10))\n",
    "                        item_set.add(item)\n",
    "                trans_item_list = list()\n",
    "                for i in range(len(left_arr)):\n",
    "                    item_name: str = left_arr[i]\n",
    "                    item: Item = find_item_by_name(item_name, item_set)\n",
    "                    trans_item: TransItem = TransItem(\n",
    "                        item, int(right_arr[i]), round(random.uniform(0.30, 0.99), 2)\n",
    "                    )\n",
    "                    trans_item_list.append(trans_item)\n",
    "                trans = Transaction(tid, trans_item_list)\n",
    "                database.append(trans)\n",
    "                tid += 1\n",
    "                if(tid > lines):\n",
    "                    return list(item_set), database\n",
    "        return list(item_set), database\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"The file at {file_path} does not exist.\")\n",
    "    except IOError as e:\n",
    "        raise IOError(f\"An error occurred while reading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_list_1, database_1 = read_aggregate_data(\"dataset/accident/accident_dataset.txt\", 20000)\n",
    "# item_list_2, database_2 = list(item_list_1), list(database_1)\n",
    "# item_list_3, database_3 = list(item_list_1), list(database_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "prob_threshold = 0.002\n",
    "min_per_threshold = 1\n",
    "max_per_threshold = 3000\n",
    "min_avg_threshold = 1\n",
    "max_avg_threshold = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs1 = topk_mining_based_on_PHUI(\n",
    "#     database_1,\n",
    "#     item_list_1,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "#     False,\n",
    "# )\n",
    "# rs1.print_items()\n",
    "# t2 = datetime.datetime.now()\n",
    "# print(\"topk_mining_based_on_PHUI(false): \" + str(len(rs1.heap)))\n",
    "# print(\"topk_mining_based_on_PHUI(false): \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs2 = topk_mining_based_on_PHUI(\n",
    "#     database_2,\n",
    "#     item_list_2,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "#     True,\n",
    "# )\n",
    "# rs2.print_items()\n",
    "# t2 = datetime.datetime.now()\n",
    "# print(\"topk_mining_based_on_PHUI(true): \" + str(len(rs2.heap)))\n",
    "# print(\"topk_mining_based_on_PHUI(true): \" + str(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = datetime.datetime.now()\n",
    "# rs3 = topk_mining_based_on_EFIM(\n",
    "#     database_3,\n",
    "#     item_list_3,\n",
    "#     k,\n",
    "#     min_per_threshold,\n",
    "#     max_per_threshold,\n",
    "#     min_avg_threshold,\n",
    "#     max_avg_threshold,\n",
    "#     prob_threshold,\n",
    "# )\n",
    "# rs3.print_items()\n",
    "# t2 = datetime.datetime.now()\n",
    "# print(\"topk_mining_based_on_EFIM: \" + str(len(rs3.heap)))\n",
    "# print(\"topk_mining_based_on_EFIM: \" + str(t2 - t1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utilities",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
